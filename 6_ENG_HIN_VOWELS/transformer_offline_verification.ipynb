{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import tensorflow as tf\n","import random\n","import re\n","import json\n","from collections import Counter\n","import copy"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from utils import tf_lower_and_remove_punct,tf_lower_and_remove_punct_1\n","from utils import masked_loss,masked_acc,beam_search_decoder\n","from utils import Transformer,CustomSchedule"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T00:08:54.677409Z","iopub.status.busy":"2024-09-24T00:08:54.676442Z","iopub.status.idle":"2024-09-24T00:08:54.681835Z","shell.execute_reply":"2024-09-24T00:08:54.680917Z","shell.execute_reply.started":"2024-09-24T00:08:54.677369Z"},"trusted":true},"outputs":[],"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","random.seed(42)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>english</th>\n","      <th>hindi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>we do the same too .</td>\n","      <td>हम भी ऐसा ही करेंगे .</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>these will take a couple of days more .</td>\n","      <td>इसमें एक दो दिन और लग जाएंगे ।</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>how much ?</td>\n","      <td>. कितना ?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>new search folder</td>\n","      <td>नया खोज फ़ोल्डर</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>life might be listening , and give you less th...</td>\n","      <td>अगर जिंदगी ने कहीं सुन लिया , तो अगली बार इससे...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             english  \\\n","0                               we do the same too .   \n","1            these will take a couple of days more .   \n","2                                         how much ?   \n","3                                  new search folder   \n","4  life might be listening , and give you less th...   \n","\n","                                               hindi  \n","0                              हम भी ऐसा ही करेंगे .  \n","1                     इसमें एक दो दिन और लग जाएंगे ।  \n","2                                          . कितना ?  \n","3                                    नया खोज फ़ोल्डर  \n","4  अगर जिंदगी ने कहीं सुन लिया , तो अगली बार इससे...  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('data/english_hindi_10k_vocab.csv',usecols = ['english','hindi'])\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["length of text_pairs  181602\n","length of train_pairs 154362\n","length of val_pairs   18160\n","length of test_pairs  9080\n"]}],"source":["text_pairs = list(zip(df['english'],df['hindi']))\n","random.seed(42)\n","random.shuffle(text_pairs)\n","\n","# Assigning  data for validation and testing set\n","num_val_samples = int(0.1*len(text_pairs))\n","num_test_samples = int(0.05*len(text_pairs))\n","num_train_samples = len(text_pairs) -  num_val_samples - num_test_samples\n","train_pairs = text_pairs[:num_train_samples]\n","val_pairs = text_pairs[num_train_samples:num_train_samples+num_val_samples]\n","test_pairs = text_pairs[num_train_samples+num_val_samples:]\n","print(f\"length of text_pairs  {len(text_pairs)}\")\n","print(f\"length of train_pairs {len(train_pairs)}\")\n","print(f\"length of val_pairs   {len(val_pairs)}\")\n","print(f\"length of test_pairs  {len(test_pairs)}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["[('force instant hide', 'त्वरित छुपाना बाध्य करें'),\n"," ('pink marble', 'गुलाबी संगमरमर'),\n"," ('i am happy with her performance .', 'मैं उसके प्रदर्शन से खुश हूं ।'),\n"," ('kolab', 'कोलाब'),\n"," ('modify task cost', 'कार्य लागत परिवर्धित करें'),\n"," ('color mode', 'रंग विधि'),\n"," ('bird tweet', 'चिड़ियों की चहचहाहट'),\n"," ('canadian aboriginal', 'कनाडियन एबॉर्जिनल'),\n"," ('it s rather cold today .', 'आज मौसम काफ़ी ठंडा है ।'),\n"," ('calendar format', 'कैलेन्डर फॉर्मेट')]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["with open(\"data/customized_val_pairs.txt\",'r',encoding = 'utf-8') as f:\n","    customized_val_pairs = f.readlines()\n","    customized_val_pairs = [tuple(i.strip('\\n').split('\\t')) for i in customized_val_pairs]\n","customized_val_pairs[:10]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["with open('Text_vectorization_file/english_vocab.json','r',encoding = 'utf-8') as f:\n","    english_vocab = json.load(f)\n","\n","with open('Text_vectorization_file/hindi_vocab.json','r',encoding = 'utf-8') as f:\n","    hindi_vocab = json.load(f)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["max_vocab_size =15000\n","sequence_length = 25\n","#Recreate the English vectorization layer with basic configuration\n","english_vectorization = tf.keras.layers.TextVectorization(\n","    max_tokens = max_vocab_size,\n","    output_mode = 'int',\n","    output_sequence_length = sequence_length,\n","    standardize = tf_lower_and_remove_punct\n",")\n","\n","\n","hindi_vectorization = tf.keras.layers.TextVectorization(\n","    max_tokens = max_vocab_size,\n","    output_mode = 'int',\n","    output_sequence_length = sequence_length+1,\n","    standardize = tf_lower_and_remove_punct_1\n",")\n","\n","english_vectorization.set_vocabulary(english_vocab)\n","hindi_vectorization.set_vocabulary(hindi_vocab)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10438\n","11697\n"]}],"source":["print(len(english_vocab))\n","print(len(hindi_vocab))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["batch_size = 64\n","def format_dataset(eng,hin):\n","    eng = english_vectorization(eng)\n","    hin = hindi_vectorization(hin)\n","    tar_in = hin[:,:-1]\n","    tar_out = hin[:,1:]\n","    return (eng,tar_in),tar_out\n","\n","def make_dataset(pairs):\n","    eng_texts, hin_texts = zip(*pairs)\n","    eng_texts = list(eng_texts)\n","    hin_texts = list(hin_texts)\n","    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, hin_texts))\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(format_dataset)\n","    return dataset\n","\n","new_val_ds = make_dataset(customized_val_pairs)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T01:42:40.716005Z","iopub.status.busy":"2024-09-24T01:42:40.715617Z","iopub.status.idle":"2024-09-24T01:42:40.721670Z","shell.execute_reply":"2024-09-24T01:42:40.720784Z","shell.execute_reply.started":"2024-09-24T01:42:40.715970Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["606\n"]}],"source":["print(len(new_val_ds))"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T01:45:41.314764Z","iopub.status.busy":"2024-09-24T01:45:41.314367Z","iopub.status.idle":"2024-09-24T01:45:41.426496Z","shell.execute_reply":"2024-09-24T01:45:41.425652Z","shell.execute_reply.started":"2024-09-24T01:45:41.314723Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 25)\n","(64, 25)\n","(64, 25)\n"]}],"source":["for (inp,tar_in),tar_out in new_val_ds.take(1):\n","    pass\n","print(inp.shape)\n","print(tar_in.shape)\n","print(tar_out.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T02:38:01.708992Z","iopub.status.busy":"2024-09-24T02:38:01.708147Z","iopub.status.idle":"2024-09-24T02:38:01.812399Z","shell.execute_reply":"2024-09-24T02:38:01.811612Z","shell.execute_reply.started":"2024-09-24T02:38:01.708953Z"},"trusted":true},"outputs":[],"source":["embed_dim = 320\n","heads = 2\n","latent = 2048\n","no_of_layers = 4\n","vocab_size_eng = len(english_vocab)\n","vocab_size_hin = len(hindi_vocab)\n","\n","transformer1 = Transformer(embedding_dim=embed_dim,num_heads=heads,dense_dim=latent,\n","                          num_layers=no_of_layers,input_vocab_size=vocab_size_eng,\n","                           output_vocab_size=vocab_size_hin)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T02:38:03.799119Z","iopub.status.busy":"2024-09-24T02:38:03.798215Z","iopub.status.idle":"2024-09-24T02:38:08.754109Z","shell.execute_reply":"2024-09-24T02:38:08.753372Z","shell.execute_reply.started":"2024-09-24T02:38:03.799078Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)               │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,883,392</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)               │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">15,574,592</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11697</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,754,737</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder (\u001b[38;5;33mEncoder\u001b[0m)               │ ?                      │    \u001b[38;5;34m11,883,392\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder (\u001b[38;5;33mDecoder\u001b[0m)               │ ?                      │    \u001b[38;5;34m15,574,592\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m11697\u001b[0m)        │     \u001b[38;5;34m3,754,737\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,212,721</span> (119.07 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,212,721\u001b[0m (119.07 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,212,721</span> (119.07 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,212,721\u001b[0m (119.07 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["logits = transformer1((inp,tar_in))\n","transformer1.summary()\n","learning_rate = CustomSchedule(d_model=embed_dim)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)\n","transformer1.compile(optimizer =optimizer,loss = masked_loss,metrics=[masked_acc])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T02:38:08.755794Z","iopub.status.busy":"2024-09-24T02:38:08.755502Z","iopub.status.idle":"2024-09-24T02:38:08.762451Z","shell.execute_reply":"2024-09-24T02:38:08.761711Z","shell.execute_reply.started":"2024-09-24T02:38:08.755763Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 345 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}],"source":["transformer1.load_weights('english_hindi_model.weights.h5')"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 551ms/step - loss: 1.4475 - masked_acc: 0.7639\n"]},{"data":{"text/plain":["[1.472076416015625, 0.760397732257843]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["transformer1.evaluate(new_val_ds)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["embed_dim = 128\n","heads = 2\n","latent = 512\n","no_of_layers = 2\n","vocab_size_eng = len(english_vocab)\n","vocab_size_hin = len(hindi_vocab)\n","\n","transformer2 = Transformer(embedding_dim=embed_dim,num_heads=heads,dense_dim=latent,\n","                          num_layers=no_of_layers,input_vocab_size=vocab_size_eng,\n","                           output_vocab_size=vocab_size_hin)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"transformer_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Encoder</span>)             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,864,448</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Decoder</span>)             │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,290,048</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11697</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,508,913</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ encoder_1 (\u001b[38;5;33mEncoder\u001b[0m)             │ ?                      │     \u001b[38;5;34m1,864,448\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ decoder_1 (\u001b[38;5;33mDecoder\u001b[0m)             │ ?                      │     \u001b[38;5;34m2,290,048\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m11697\u001b[0m)        │     \u001b[38;5;34m1,508,913\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,663,409</span> (21.60 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,663,409\u001b[0m (21.60 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,663,409</span> (21.60 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,663,409\u001b[0m (21.60 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"}],"source":["logits2 = transformer2((inp,tar_in))\n","transformer2.summary()\n","learning_rate = CustomSchedule(d_model=embed_dim)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n","                                     epsilon=1e-9)\n","transformer2.compile(optimizer =optimizer,loss = masked_loss,metrics=[masked_acc])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 1 variables whereas the saved optimizer has 177 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}],"source":["transformer2.load_weights(\"eng_hin.weights.h5\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 159ms/step - loss: 1.6188 - masked_acc: 0.7519\n"]},{"data":{"text/plain":["[1.6467397212982178, 0.7485809922218323]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["transformer2.evaluate(new_val_ds)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T02:32:31.432484Z","iopub.status.busy":"2024-09-24T02:32:31.431460Z","iopub.status.idle":"2024-09-24T02:32:31.496991Z","shell.execute_reply":"2024-09-24T02:32:31.496244Z","shell.execute_reply.started":"2024-09-24T02:32:31.432421Z"},"trusted":true},"outputs":[],"source":["hindi_vocab = hindi_vectorization.get_vocabulary()\n","hindi_index_lookup = dict(zip(range(len(hindi_vocab)), hindi_vocab))\n","max_decoded_sentence_length = 25\n","\n","def decode_sentence(model,input_sentence):\n","    tokenized_input_sentence = english_vectorization([input_sentence])\n","    decoded_sentence = \"[SOS]\"\n","    for i in range(max_decoded_sentence_length):\n","        tokenized_target_sentence = hindi_vectorization([decoded_sentence])[:, :-1]\n","        predictions = model([tokenized_input_sentence, tokenized_target_sentence])\n","        # print(predictions)\n","        # next_tokens,next_logits = tf.nn.top_k(predictions,k = 2)\n","        # print(next_tokens)\n","        # print(next_logits)\n","        sampled_token_index = tf.argmax(predictions[0, i, :]).numpy().item(0)\n","        # print(sampled_token_index)\n","        sampled_token = hindi_index_lookup[sampled_token_index]\n","        # print(sampled_token)\n","        decoded_sentence += \" \" + sampled_token\n","        if sampled_token == \"[EOS]\":\n","            break\n","    return decoded_sentence.lstrip(\"[SOS]\").rstrip(\"[EOS]\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":[" आवाज़ \n"," आवाज़ \n"," वस्तु प्रतीक \n"," संगीत \n"]}],"source":["text = \"Chemistry\"\n","print(decode_sentence(transformer1,text))\n","print(beam_search_decoder(model =transformer1,input_sentence =text,beam_width=3,\n","                        english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                        hindi_index_lookup=hindi_index_lookup))\n","print(decode_sentence(transformer2,text))\n","print(beam_search_decoder(model =transformer2,input_sentence =text,beam_width=3,\n","                        english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                        hindi_index_lookup=hindi_index_lookup))"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T03:10:58.432766Z","iopub.status.busy":"2024-09-24T03:10:58.431705Z","iopub.status.idle":"2024-09-24T03:11:07.930602Z","shell.execute_reply":"2024-09-24T03:11:07.929645Z","shell.execute_reply.started":"2024-09-24T03:10:58.432710Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["input: initial file chooser folder\n","model1 translations\n","normal_tranlsation_     :  आरंभिक फाइल चयनक फ़ोल्डर \n","beam_search_translation:  आरंभिक फाइल चयनक फ़ोल्डर \n","model2 translations\n","normal_tranlsation_     :  आरंभिक फाइल चयनक फ़ोल्डर \n","beam_search_translation:  आरंभिक फाइल चयनक फ़ोल्डर \n","original__sentence     :  प्रारंभिक फ़ाइल चयनकर्ता फ़ोल्डर\n","\n","input: so the first thing to figure out about this hyperbola is ,\n","model1 translations\n","normal_tranlsation_     :  तो पहली बात यह है के बारे में , इस अति परवलय समझ से है \n","beam_search_translation:  तो पहली बात यह है के बारे में , इस अति परवलय समझ से है \n","model2 translations\n","normal_tranlsation_     :  तो पहली बात यह है के बारे में पहली बात यह है , \n","beam_search_translation:  तो पहली बात यह है के बारे में पहली बात , \n","original__sentence     :  तो , पहली बात यह है के बारे में इस अति परवलय समझ से बाहर है\n","\n","input: . what does right to information mean ?\n","model1 translations\n","normal_tranlsation_     :  सूचना अधिकार का क्या मतलब है ? \n","beam_search_translation:  सूचना अधिकार का क्या मतलब है ? \n","model2 translations\n","normal_tranlsation_     :  जानकारी सूचना अधिकार का क्या अर्थ है ? \n","beam_search_translation:  सूचना अधिकार का क्या अर्थ है ? \n","original__sentence     :  . सूचना अधिकार का क्या अर्थ है ?\n","\n","input: but i don t think that it s strange at all .\n","model1 translations\n","normal_tranlsation_     :  लेकिन मुझे नहीं लगता है कि यह सब कुछ अजीब है । \n","beam_search_translation:  लेकिन मुझे नहीं लगता है कि यह सब कुछ अजीब है \n","model2 translations\n","normal_tranlsation_     :  लेकिन मुझे नहीं लगता कि यह भी अजीब है । \n","beam_search_translation:  लेकिन मुझे नहीं लगता कि यह भी अजीब है । \n","original__sentence     :  पर मेरे खयाल से यह बिलकुल भी अजीब नहीं है ।\n","\n","input: that is also a positive .\n","model1 translations\n","normal_tranlsation_     :  यह भी सकारात्मक है । \n","beam_search_translation:  यह भी सकारात्मक है । \n","model2 translations\n","normal_tranlsation_     :  यह भी सकारात्मक है । \n","beam_search_translation:  यह भी सकारात्मक है । \n","original__sentence     :  वह भी सकारात्मक अर्थ में .\n","\n"]}],"source":["random.seed(42)\n","for _ in range(5):\n","    input_sentence,output_sentence = random.choice(train_pairs)\n","    # input_sentence = input_sentence.lower()\n","    # input_sentence = input_sentence.translate(str.maketrans('', '', strip_chars))\n","    translated1 = decode_sentence(transformer1,input_sentence)\n","    translated2 = beam_search_decoder(model =transformer1,input_sentence =input_sentence,beam_width=3,\n","                                      english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                                      hindi_index_lookup=hindi_index_lookup)\n","    translated3 = decode_sentence(transformer2,input_sentence)\n","    translated4 = beam_search_decoder(model =transformer2,input_sentence =input_sentence,beam_width=3,\n","                                      english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                                      hindi_index_lookup=hindi_index_lookup)\n","    print(f\"input: {input_sentence}\")\n","    print(\"model1 translations\")\n","    print(f\"normal_tranlsation_     : {translated1}\")\n","    print(f\"beam_search_translation: {translated2}\")\n","    print(\"model2 translations\")\n","    print(f\"normal_tranlsation_     : {translated3}\")\n","    print(f\"beam_search_translation: {translated4}\")\n","    print(f\"original__sentence     :  {output_sentence}\")\n","    print()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T03:12:28.677473Z","iopub.status.busy":"2024-09-24T03:12:28.676364Z","iopub.status.idle":"2024-09-24T03:12:36.456179Z","shell.execute_reply":"2024-09-24T03:12:36.455238Z","shell.execute_reply.started":"2024-09-24T03:12:28.677414Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["input: and carry the .\n","model1 translations\n","normal_tranlsation_     :  को हासिल ले लो \n","beam_search_translation:  को हासिल ले लो \n","model2 translations\n","normal_tranlsation_     :  और आगे ले जाते है \n","beam_search_translation:  और आगे ले जाते है \n","original__sentence     :  और को हासिल ले लेते हैं\n","\n","input: india is a country in south asia .\n","model1 translations\n","normal_tranlsation_     :  भारत देश का एक देश है दक्षिण एशिया \n","beam_search_translation:  दक्षिण एशिया का एक देश है । \n","model2 translations\n","normal_tranlsation_     :  भारत दक्षिण एशिया का भारत है । \n","beam_search_translation:  भारत दक्षिण एशिया का भारत है । \n","original__sentence     :  भारत देश उत्तरी गोलार्ध में स्थित है ।\n","\n","input: we should first make sure that it s not in this world .\n","model1 translations\n","normal_tranlsation_     :  सबसे पहले यह इस दुनिया में नहीं है कि यह सुनिश्चित हों \n","beam_search_translation:  सबसे पहले यह है कि इस संसार में नहीं है \n","model2 translations\n","normal_tranlsation_     :  हम पहली बार को यह यकीन करना चाहिए कि ये नही है \n","beam_search_translation:  हम पहली बार को इस संसार में है \n","original__sentence     :  हमे पहले यह निश्चित करना चाहिए कि यह इस दुनिया का नहीं है ।\n","\n","input: job type\n","model1 translations\n","normal_tranlsation_     :  कार्य क़िस्मः \n","beam_search_translation:  कार्य क़िस्मः \n","model2 translations\n","normal_tranlsation_     :  कार्य क़िस्म \n","beam_search_translation:  कार्य क़िस्म \n","original__sentence     :  कार्य क़िस्म\n","\n","input: but we kind of chose this shape .\n","model1 translations\n","normal_tranlsation_     :  लेकिन , इस तरह की आकृति चुने थे \n","beam_search_translation:  लेकिन हमने इस तरह की आकृति को चुना \n","model2 translations\n","normal_tranlsation_     :  लेकिन हमने इस तरह की आकृति को चुना \n","beam_search_translation:  लेकिन हमने इस तरह की आकृति को चुना \n","original__sentence     :  लेकिन हमने इस तरह की आकृति को चुना .\n","\n"]}],"source":["random.seed(42)\n","for _ in range(5):\n","    input_sentence,output_sentence = random.choice(val_pairs)\n","    # input_sentence = input_sentence.lower()\n","    # input_sentence = input_sentence.translate(str.maketrans('', '', strip_chars))\n","    translated1 = decode_sentence(transformer1,input_sentence)\n","    translated2 = beam_search_decoder(model =transformer1,input_sentence =input_sentence,beam_width=3,\n","                                      english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                                      hindi_index_lookup=hindi_index_lookup)\n","    translated3 = decode_sentence(transformer2,input_sentence)\n","    translated4 = beam_search_decoder(model =transformer2,input_sentence =input_sentence,beam_width=3,\n","                                      english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                                      hindi_index_lookup=hindi_index_lookup)\n","    print(f\"input: {input_sentence}\")\n","    print(\"model1 translations\")\n","    print(f\"normal_tranlsation_     : {translated1}\")\n","    print(f\"beam_search_translation: {translated2}\")\n","    print(\"model2 translations\")\n","    print(f\"normal_tranlsation_     : {translated3}\")\n","    print(f\"beam_search_translation: {translated4}\")\n","    print(f\"original__sentence     :  {output_sentence}\")\n","    print()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T03:14:05.688717Z","iopub.status.busy":"2024-09-24T03:14:05.688308Z","iopub.status.idle":"2024-09-24T03:14:12.696387Z","shell.execute_reply":"2024-09-24T03:14:12.695407Z","shell.execute_reply.started":"2024-09-24T03:14:05.688680Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["input: so we wanted to win this match .\n","model1 translations\n","normal_tranlsation_     :  इसलिए हम इस मैच को जीतना चाहते थे । \n","beam_search_translation:  इसलिए हम इस मैच को जीतना चाहते थे । \n","model2 translations\n","normal_tranlsation_     :  इसलिए हम इस मैच को जीतना चाहते थे । \n","beam_search_translation:  इसलिए हम यह मैच जीतना चाहते थे । \n","original__sentence     :  इसलिए हम इस मैच को जीतना चाहते थे .\n","\n","input: it will have a common name all over the country .\n","model1 translations\n","normal_tranlsation_     :  यह देश भर में एक सामान्य नाम है । \n","beam_search_translation:  यह देश भर में एक सामान्य नाम है । \n","model2 translations\n","normal_tranlsation_     :  यह सब देश में एक ही नाम होगा । \n","beam_search_translation:  देश भर में यह सब कुछ नाम होगा । \n","original__sentence     :  देश भर में दुकान के लिए एक ही नाम होगा ।\n","\n","input: please select a folder below\n","model1 translations\n","normal_tranlsation_     :  कृपया नीचे एक फ़ोल्डर चुनें \n","beam_search_translation:  कृपया नीचे एक फ़ोल्डर चुनें \n","model2 translations\n","normal_tranlsation_     :  नीचे कृपया नीचे फ़ोल्डर यहाँ चुनें \n","beam_search_translation:  नीचे कृपया नीचे फ़ोल्डर चुनें \n","original__sentence     :  कृपया एक फोल्डर नीचे से चुनें\n","\n","input: and second of all ,\n","model1 translations\n","normal_tranlsation_     :  और दूसरा , \n","beam_search_translation:  और दूसरा , \n","model2 translations\n","normal_tranlsation_     :  और दूसरा , \n","beam_search_translation:  और दूसरा , \n","original__sentence     :  और दूसरा ,\n","\n","input: end of a short break\n","model1 translations\n","normal_tranlsation_     :  छोटे ब्रेक की समाप्ति \n","beam_search_translation:  छोटे ब्रेक की समाप्ति \n","model2 translations\n","normal_tranlsation_     :  छोटे ब्रेक की समाप्ति \n","beam_search_translation:  छोटे ब्रेक की समाप्ति \n","original__sentence     :  छोटे ब्रेक की समाप्ति\n","\n"]}],"source":["random.seed(42)\n","for _ in range(5):\n","    input_sentence,output_sentence = random.choice(test_pairs)\n","    # input_sentence = input_sentence.lower()\n","    # input_sentence = input_sentence.translate(str.maketrans('', '', strip_chars))\n","    translated1 = decode_sentence(transformer1,input_sentence)\n","    translated2 = beam_search_decoder(model =transformer1,input_sentence =input_sentence,beam_width=3,\n","                                      english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                                      hindi_index_lookup=hindi_index_lookup)\n","    translated3 = decode_sentence(transformer2,input_sentence)\n","    translated4 = beam_search_decoder(model =transformer2,input_sentence =input_sentence,beam_width=3,\n","                                      english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                                      hindi_index_lookup=hindi_index_lookup)\n","    print(f\"input: {input_sentence}\")\n","    print(\"model1 translations\")\n","    print(f\"normal_tranlsation_     : {translated1}\")\n","    print(f\"beam_search_translation: {translated2}\")\n","    print(\"model2 translations\")\n","    print(f\"normal_tranlsation_     : {translated3}\")\n","    print(f\"beam_search_translation: {translated4}\")\n","    print(f\"original__sentence     :  {output_sentence}\")\n","    print()\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T03:14:34.014184Z","iopub.status.busy":"2024-09-24T03:14:34.013291Z","iopub.status.idle":"2024-09-24T03:14:34.018316Z","shell.execute_reply":"2024-09-24T03:14:34.017337Z","shell.execute_reply.started":"2024-09-24T03:14:34.014140Z"},"trusted":true},"outputs":[],"source":["my_text = [\"where are you ?\",\n","          \"i am not one of them \",\n","          \"what do you think about them ?\",\n","          \"today is a good day\",\n","          \"who are you?\",]"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-09-24T03:14:38.364088Z","iopub.status.busy":"2024-09-24T03:14:38.363089Z","iopub.status.idle":"2024-09-24T03:14:44.286212Z","shell.execute_reply":"2024-09-24T03:14:44.285171Z","shell.execute_reply.started":"2024-09-24T03:14:38.364048Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["sentence:  where are you ?\n","model_1\n","normal_search_result:   कहां हैं ? \n","beam_search_result  :   तुम कहाँ हो ? \n","model_2\n","normal_search_result:   तुम कहाँ हो ? \n","beam_search_result  :   तुम कहाँ हो ? \n","\n","sentence:  i am not one of them \n","model_1\n","normal_search_result:   मैं उनमें से एक नहीं हूँ \n","beam_search_result  :   मैं उनमें से एक नहीं हूँ \n","model_2\n","normal_search_result:   मैं उनमें से एक नहीं हूँ । \n","beam_search_result  :   मैं उनमें से एक नहीं हूँ \n","\n","sentence:  what do you think about them ?\n","model_1\n","normal_search_result:   तुम्हारे बारे में क्या लगता है । \n","beam_search_result  :   तुम्हारे बारे में क्या लगता है । \n","model_2\n","normal_search_result:   क्या आपको उनकी बारे में क्या लगता है ? \n","beam_search_result  :   उनके बारे में क्या सोच रहे हो ? \n","\n","sentence:  today is a good day\n","model_1\n","normal_search_result:   आज का दिन अच्छा है \n","beam_search_result  :   आज का दिन अच्छा है \n","model_2\n","normal_search_result:   आज अच्छा दिन है । \n","beam_search_result  :   आज अच्छा दिन है । \n","\n","sentence:  who are you?\n","model_1\n","normal_search_result:   तुम कौन हो ? \n","beam_search_result  :   तुम कौन हो ? \n","model_2\n","normal_search_result:   आप लोग हैं कौन ? \n","beam_search_result  :   तुम कौन हो ? \n","\n"]}],"source":["for i in my_text:\n","    x = decode_sentence(transformer1,i)\n","    y = beam_search_decoder(model =transformer1,input_sentence =i,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup)\n","    x1 = decode_sentence(transformer2,i)\n","    y1 = beam_search_decoder(model =transformer2,input_sentence =i,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup)\n","    print('sentence: ',i)\n","    print('model_1')\n","    print('normal_search_result: ',x)\n","    print('beam_search_result  : ',y)\n","    print(\"model_2\")\n","    print('normal_search_result: ',x1)\n","    print('beam_search_result  : ',y1)\n","    print()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["my_text_1 = [\"hi my name is tom\",\n","           \"how are you people\",\n","           \"once again\",\n","           \" hello, my name is tom . how are you ?\",\n","           \"Hope today is a good day\",\n","\n","           ]\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n","c:\\Users\\sivat\\Anaconda3\\envs\\tensorflow-env\\lib\\site-packages\\keras\\src\\layers\\layer.py:934: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["sentence:  hi my name is tom\n","model_1\n","normal_search_result:   मेरा नाम टॉम है । \n","beam_search_result  :   मेरा नाम टॉम है । \n","model2\n","normal_search_result:   लिखा हुआ नाम टॉम \n","beam_search_result  :   लिखा हुआ नाम टॉम \n","\n","sentence:  how are you people\n","model_1\n","normal_search_result:   कैसे हैं जनता \n","beam_search_result  :   लोग कैसे हैं \n","model2\n","normal_search_result:   आप लोग कैसे हैं \n","beam_search_result  :   आप लोग कैसे हैं \n","\n","sentence:  once again\n","model_1\n","normal_search_result:   और एक बार \n","beam_search_result  :   और एक बार \n","model2\n","normal_search_result:   एक बार फिर \n","beam_search_result  :   एक बार फिर \n","\n","sentence:   hello, my name is tom . how are you ?\n","model_1\n","normal_search_result:   नमस्ते , आप टॉम का नाम है । आप कैसे हैं ? \n","beam_search_result  :   नमस्ते , मेरा नाम टॉम है । आप कैसे हैं ? \n","model2\n","normal_search_result:   नमस्ते , मेरा नाम है टॉम । आप कैसे हैं ? \n","beam_search_result  :   नमस्ते , मेरा नाम है टॉम । आप कैसे हैं ? \n","\n","sentence:  Hope today is a good day\n","model_1\n","normal_search_result:   उम्मीद है आज का दिन ठीक है \n","beam_search_result  :   उम्मीद है आज का दिन ठीक है \n","model2\n","normal_search_result:   आज उम्मीद का दिन ठीक है \n","beam_search_result  :   आशा है कि आज अच्छा दिन \n","\n"]}],"source":["\n","for i in my_text_1:\n","    x = decode_sentence(transformer1,i)\n","    y = beam_search_decoder(model =transformer1,input_sentence =i,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup)\n","    x1 = decode_sentence(transformer2,i)\n","    y1 = beam_search_decoder(model =transformer2,input_sentence =i,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup)\n","    print('sentence: ',i)\n","    print('model_1')\n","    print('normal_search_result: ',x)\n","    print('beam_search_result  : ',y)\n","    print(\"model2\")\n","    print('normal_search_result: ',x1)\n","    print('beam_search_result  : ',y1)\n","    print()\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" मैं सुबह के लिए पक्षी कुंजी की बात करें \n"," मैं सुबह की नई डाक की सारी खबर सुनता हूं \n"]}],"source":["text = \"i listen to bird tweet in the morning\"\n","print(decode_sentence(transformer1,text))\n","print(decode_sentence(transformer2,text))\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" मैं सुबह पक्षियों को देखे की देखे \n"," मैं सुबह के समय की बिलकुल खबर सुनता हूं \n"]}],"source":["print(beam_search_decoder(model =transformer1,input_sentence =text,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup))\n","print(beam_search_decoder(model =transformer2,input_sentence =text,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["sentence:  ported\n","model_1\n","normal_search_result:   मामले हैं पोर्टेड \n","beam_search_result  :   पोर्टेड \n","model2\n","normal_search_result:   ही पोर्टेड \n","beam_search_result  :   पोर्टेड \n","\n","sentence:  alignat\n","model_1\n","normal_search_result:   लकीर \n","beam_search_result  :   लकीर \n","model2\n","normal_search_result:   लकीर \n","beam_search_result  :   लकीर \n","\n","sentence:  neighborhood\n","model_1\n","normal_search_result:   पड़ोस \n","beam_search_result  :   पड़ोस \n","model2\n","normal_search_result:   पड़ोस \n","beam_search_result  :   पड़ोस \n","\n","sentence:  breathe\n","model_1\n","normal_search_result:   साँस \n","beam_search_result  :   साँस \n","model2\n","normal_search_result:   साँस \n","beam_search_result  :   साँस \n","\n","sentence:  eleven\n","model_1\n","normal_search_result:   ग्यारह \n","beam_search_result  :   ग्यारह \n","model2\n","normal_search_result:   स्तर \n","beam_search_result  :   स्तर \n","\n"]}],"source":["random.seed(24)\n","my_text_2 = random.sample(english_vocab,5)\n","for i in my_text_2:\n","    x = decode_sentence(transformer1,i)\n","    y = beam_search_decoder(model =transformer1,input_sentence =i,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup)\n","    x1 = decode_sentence(transformer2,i)\n","    y1 = beam_search_decoder(model =transformer2,input_sentence =i,beam_width=3,\n","                            english_vectorization=english_vectorization,hindi_vectorization=hindi_vectorization,\n","                            hindi_index_lookup=hindi_index_lookup)\n","    print('sentence: ',i)\n","    print('model_1')\n","    print('normal_search_result: ',x)\n","    print('beam_search_result  : ',y)\n","    print(\"model2\")\n","    print('normal_search_result: ',x1)\n","    print('beam_search_result  : ',y1)\n","    print()\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" कल प्रदर्शित प्रशिक्षण \n"," कल प्रदर्शित प्रशिक्षण \n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":159647,"sourceId":365728,"sourceType":"datasetVersion"},{"datasetId":492138,"sourceId":915334,"sourceType":"datasetVersion"},{"datasetId":789090,"sourceId":1355361,"sourceType":"datasetVersion"},{"datasetId":2502545,"sourceId":4246862,"sourceType":"datasetVersion"},{"datasetId":3553479,"sourceId":6190858,"sourceType":"datasetVersion"},{"datasetId":4385984,"sourceId":7530378,"sourceType":"datasetVersion"},{"datasetId":5741075,"sourceId":9446283,"sourceType":"datasetVersion"},{"datasetId":5751733,"sourceId":9460732,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}

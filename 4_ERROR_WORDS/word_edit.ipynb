{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/words_alpha.txt','r') as f:\n",
    "    data =f.readlines()\n",
    "    vocabulary = [x.strip('\\n') for x in data]\n",
    "vocabulary = set(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seq',\n",
       " 'gastrostomize',\n",
       " 'nimblewit',\n",
       " 'copalite',\n",
       " 'milting',\n",
       " 'seam',\n",
       " 'tentamen',\n",
       " 'anhalouidine',\n",
       " 'gemellus',\n",
       " 'transelementary']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list(vocabulary)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(word):\n",
    "    word = word.lower().strip()\n",
    "    word =\"\".join([i for i in word if i.isalpha()])\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "list_ex = ['hello','HeLlO','he56ll90o']\n",
    "for i in list_ex:\n",
    "    print(process_word(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_letter_ops(word):\n",
    "   split_word = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "   # print(split_word)\n",
    "\n",
    "   delete_letter = [L + R[1:] for (L,R) in split_word if R]\n",
    "   # print(delete_letter)\n",
    "   return delete_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ello', 'hllo', 'helo', 'helo', 'hell']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removing_letter_ops('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_letter_ops(word):\n",
    "    split_word = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    # print(split_word)\n",
    "    switch_letter = [L[:-1]+R[0]+L[-1]+R[1:] for L,R in split_word if (L) and (R)]\n",
    "    # print(switch_letter)\n",
    "    return switch_letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afst', 'fsat', 'fats']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_letter_ops('fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_letter_ops(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    # print(len(letters))\n",
    "    split_word = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    # print(split_word)\n",
    "\n",
    "    replace_letter = [L[:-1] + i + R[::] for L,R in split_word if L for i in letters]\n",
    "\n",
    "    while word in replace_letter:\n",
    "        replace_letter.remove(word)\n",
    "\n",
    "    replace_letter = list(set(replace_letter))\n",
    "    replace_letter = sorted(replace_letter)\n",
    "    \n",
    "    # print(len(replace_letter))\n",
    "    return replace_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 words:  ['aast', 'bast', 'cast', 'dast', 'east', 'faat', 'fabt', 'fact', 'fadt', 'faet']\n"
     ]
    }
   ],
   "source": [
    "x = replace_letter_ops('fast')\n",
    "print('first 10 words: ',x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letter_ops(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    split_word = [(word[:i],word[i:]) for i in range(len(word)+1)]\n",
    "    # print(split_word)\n",
    "\n",
    "    insert_letter = [L + i +R for L,R in split_word for i in letters]\n",
    "    # print(len(insert_letter))\n",
    "    return insert_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afast', 'bfast', 'cfast', 'dfast', 'efast', 'ffast', 'gfast', 'hfast', 'ifast', 'jfast']\n"
     ]
    }
   ],
   "source": [
    "x = insert_letter_ops('fast')\n",
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word):\n",
    "    word = word.lower()\n",
    "    one_ops = set()\n",
    "\n",
    "    del_data = removing_letter_ops(word)\n",
    "    one_ops.update(del_data)\n",
    "\n",
    "    insert_data = insert_letter_ops(word)\n",
    "    one_ops.update(insert_data)\n",
    "\n",
    "    replace_data = replace_letter_ops(word)\n",
    "    one_ops.update(replace_data)\n",
    "\n",
    "    switch_data = switch_letter_ops(word)\n",
    "    one_ops.update(switch_data)\n",
    "\n",
    "    return set(one_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['clingy', 'cringe', 'fringy', 'ringy']\n"
     ]
    }
   ],
   "source": [
    "x = edit_one_letter('cringy')\n",
    "x = x & vocabulary\n",
    "print(len(x))\n",
    "print(list(x)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letter(word):\n",
    "    two_ops = set()\n",
    "    \n",
    "    my_words = edit_one_letter(word)\n",
    "    for i in my_words:\n",
    "        data = edit_one_letter(i)\n",
    "        two_ops.update(data)\n",
    "    \n",
    "    return set(two_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "['stringy', 'craggy', 'clinty', 'rings', 'rangy', 'crony', 'swingy', 'criey', 'ching', 'bingy']\n"
     ]
    }
   ],
   "source": [
    "x = edit_two_letter('cringy')\n",
    "x = x & vocabulary\n",
    "print(len(x))\n",
    "print(list(x)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_three_letter(word):\n",
    "    three_ops = set()\n",
    "    \n",
    "    my_words = edit_two_letter(word)\n",
    "    for i in my_words:\n",
    "        data = edit_one_letter(i)\n",
    "        three_ops.update(data)\n",
    "    \n",
    "    return set(three_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word:  5\n",
      "length of first, second and third edits:  285      36860       2963330\n"
     ]
    }
   ],
   "source": [
    "words = ['carth']\n",
    "for i in words:\n",
    "    print('length of word: ', len(i))\n",
    "    list1 = list(set(edit_one_letter(i)))\n",
    "    # print(list1[:10])\n",
    "    list2 = list(set(edit_two_letter(i)))\n",
    "    # print(list2[:10])\n",
    "    list3 = list(set(edit_three_letter(i)))\n",
    "    print('length of first, second and third edits: ',len(list1),'    ',len(list2),'     ',len(list3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestions_1st_time(word,vocab_list = None):\n",
    "    suggestions =set()\n",
    "    processed_word = process_word(word)\n",
    "    if processed_word in vocab_list:\n",
    "        suggestions.update({processed_word})\n",
    "    \n",
    "    my_words1 = edit_one_letter(word) & vocab_list\n",
    "    suggestions.update(my_words1)\n",
    "\n",
    "\n",
    "    words2 = edit_two_letter(word)\n",
    "    my_words2 = words2 & vocab_list\n",
    "    suggestions.update(my_words2)\n",
    "\n",
    "    words2 = list(words2)\n",
    "    random.seed(42)\n",
    "    random.shuffle(words2)\n",
    "    words2 = words2[:10000]\n",
    "\n",
    "    words = [edit_one_letter(x) & vocab_list for x in words2] \n",
    " \n",
    "    suggestions.update(*words)\n",
    "    req_words = list(my_words1) +list(my_words2-my_words1) +list(suggestions -my_words1.union(my_words2))\n",
    "\n",
    "    return suggestions,req_words\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['renormalization', 'normalization']\n"
     ]
    }
   ],
   "source": [
    "suggestions1,words = suggestions_1st_time('abnormalization',vocab_list = vocabulary)\n",
    "# print(len(suggestions1))\n",
    "print(len(words))\n",
    "# print(list(suggestions1)[:10])\n",
    "print(words[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggestions_2nd_time(word2,suggestions1, vocab_list = None,n = None):\n",
    "    suggestions2 = set()\n",
    "    processed_word = process_word(word2)\n",
    "    if processed_word in vocab_list:\n",
    "        suggestions2.update({processed_word})\n",
    "    \n",
    "    my_words1 = edit_one_letter(word2) & vocab_list\n",
    "\n",
    "    suggestions2.update(my_words1)\n",
    "\n",
    "    common_suggestions = suggestions1 & suggestions2\n",
    "    len_csug = len(common_suggestions)\n",
    "\n",
    "    if len_csug>=n:\n",
    "        return list(common_suggestions)\n",
    "    \n",
    "    words2 = edit_two_letter(word2)\n",
    "    my_words2 = words2 & vocab_list \n",
    "\n",
    "    suggestions2.update(my_words2)\n",
    "\n",
    "    length = len(suggestions2.union(suggestions1))\n",
    "\n",
    "    if length >=n:\n",
    "        common_suggestions = suggestions1 & suggestions2\n",
    "        suggestions = list(common_suggestions) + list(suggestions2 - common_suggestions) + list(suggestions1 - common_suggestions)\n",
    "        return suggestions\n",
    "    \n",
    "\n",
    "    words2 = list(words2)\n",
    "    random.seed(42)\n",
    "    random.shuffle(words2)\n",
    "\n",
    "    if len(word2)>4:\n",
    "        words2 = words2[:30000]\n",
    "\n",
    "    for i in words2:\n",
    "        suggestions2.update(edit_one_letter(i) & vocab_list)\n",
    "        if len(suggestions2.union(suggestions1))>=n:\n",
    "            break\n",
    "\n",
    "    \n",
    "    common_suggestions = suggestions1 & suggestions2\n",
    "    suggestions = list(common_suggestions) + list(suggestions2 - common_suggestions) + list(suggestions1 - common_suggestions)\n",
    "\n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['renormalization', 'normalization', 'formalization', 'normalizations']\n"
     ]
    }
   ],
   "source": [
    "word1,word2 = 'abnormalization','abnormalization'\n",
    "# suggestions1,_ = correct_words_1st_time(word1,vocab_list = vocabulary)\n",
    "suggestions = suggestions_2nd_time(word2,suggestions1,vocab_list=vocabulary,n = 5)\n",
    "print(len(suggestions))\n",
    "print(suggestions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

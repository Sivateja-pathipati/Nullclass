{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9495164,"sourceType":"datasetVersion","datasetId":5777788}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:56:46.261967Z","iopub.execute_input":"2024-09-27T12:56:46.262270Z","iopub.status.idle":"2024-09-27T12:56:47.219179Z","shell.execute_reply.started":"2024-09-27T12:56:46.262236Z","shell.execute_reply":"2024-09-27T12:56:47.218244Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/english-spanish/eng_spa.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/english-spanish/eng_spa.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:04.198883Z","iopub.execute_input":"2024-09-27T12:57:04.199459Z","iopub.status.idle":"2024-09-27T12:57:04.203810Z","shell.execute_reply.started":"2024-09-27T12:57:04.199417Z","shell.execute_reply":"2024-09-27T12:57:04.202918Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random\nimport string\nimport re\nimport json\nimport copy","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:05.737252Z","iopub.execute_input":"2024-09-27T12:57:05.738099Z","iopub.status.idle":"2024-09-27T12:57:17.704911Z","shell.execute_reply.started":"2024-09-27T12:57:05.738047Z","shell.execute_reply":"2024-09-27T12:57:17.704095Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path,names= ['English','Spanish'],index_col =0)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:26.168143Z","iopub.execute_input":"2024-09-27T12:57:26.169009Z","iopub.status.idle":"2024-09-27T12:57:26.590993Z","shell.execute_reply.started":"2024-09-27T12:57:26.168970Z","shell.execute_reply":"2024-09-27T12:57:26.590146Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:31.315444Z","iopub.execute_input":"2024-09-27T12:57:31.316207Z","iopub.status.idle":"2024-09-27T12:57:31.333882Z","shell.execute_reply.started":"2024-09-27T12:57:31.316168Z","shell.execute_reply":"2024-09-27T12:57:31.332976Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  English                Spanish\n0     Go.      [start] Ve. [end]\n1     Go.    [start] Vete. [end]\n2     Go.    [start] Vaya. [end]\n3     Go.  [start] Váyase. [end]\n4     Hi.    [start] Hola. [end]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Spanish</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>[start] Ve. [end]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Go.</td>\n      <td>[start] Vete. [end]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Go.</td>\n      <td>[start] Vaya. [end]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Go.</td>\n      <td>[start] Váyase. [end]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hi.</td>\n      <td>[start] Hola. [end]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:32.497639Z","iopub.execute_input":"2024-09-27T12:57:32.498549Z","iopub.status.idle":"2024-09-27T12:57:32.504286Z","shell.execute_reply.started":"2024-09-27T12:57:32.498508Z","shell.execute_reply":"2024-09-27T12:57:32.503306Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"118964"},"metadata":{}}]},{"cell_type":"code","source":"df['Spanish'] = df['Spanish'].apply(lambda x:x.lstrip('[start]'))\ndf['Spanish'] = df['Spanish'].apply(lambda x:x.rstrip('[end]'))\ndf['Spanish']","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:35.007766Z","iopub.execute_input":"2024-09-27T12:57:35.008157Z","iopub.status.idle":"2024-09-27T12:57:35.128541Z","shell.execute_reply.started":"2024-09-27T12:57:35.008121Z","shell.execute_reply":"2024-09-27T12:57:35.127565Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0                                                      Ve. \n1                                                    Vete. \n2                                                    Vaya. \n3                                                  Váyase. \n4                                                    Hola. \n                                ...                        \n118959     Hay cuatro causas principales de muertes rela...\n118960     Hay madres y padres que se quedan despiertos ...\n118961     Una huella de carbono es la cantidad de conta...\n118962     Como suele haber varias páginas web sobre cua...\n118963     Si quieres sonar como un hablante nativo, deb...\nName: Spanish, Length: 118964, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"data = list(zip(df['English'],df['Spanish']))\nrandom.seed(42)\nrandom.shuffle(data)\ndata[:5]","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:37.445827Z","iopub.execute_input":"2024-09-27T12:57:37.446223Z","iopub.status.idle":"2024-09-27T12:57:37.593476Z","shell.execute_reply.started":"2024-09-27T12:57:37.446186Z","shell.execute_reply":"2024-09-27T12:57:37.592509Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"[('How long have you been studying Hungarian?',\n  ' ¿Cuánto tiempo has estado estudiando húngaro? '),\n ('Do you really want to be here?', ' ¿Realmente querés estar acá? '),\n ('She is as beautiful as Snow White.', ' Ella es bella como Blancanieves. '),\n (\"There are few men who don't know that.\",\n  ' Hay pocos hombres que no lo saben. '),\n ('Tom changes channels during commercials.',\n  ' Tom cambia de canal durante los comerciales. ')]"},"metadata":{}}]},{"cell_type":"code","source":"len_val = int(0.2 * len(data))\nlen_train = len(data) - len_val\ntrain_pairs = data[:len_train]\nval_pairs = data[len_train:len_train + len_val]\n\nprint(f\"{len(data)} total pairs\")\nprint(f\"{len(train_pairs)} training pairs\")\nprint(f\"{len(val_pairs)} validation pairs\")","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:38.800587Z","iopub.execute_input":"2024-09-27T12:57:38.801309Z","iopub.status.idle":"2024-09-27T12:57:38.808951Z","shell.execute_reply.started":"2024-09-27T12:57:38.801268Z","shell.execute_reply":"2024-09-27T12:57:38.807994Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"118964 total pairs\n95172 training pairs\n23792 validation pairs\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Vectorizing the data","metadata":{}},{"cell_type":"code","source":"vocab_size = 12000\nsequence_length = 20\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:57:55.576191Z","iopub.execute_input":"2024-09-27T12:57:55.576601Z","iopub.status.idle":"2024-09-27T12:57:55.581114Z","shell.execute_reply.started":"2024-09-27T12:57:55.576563Z","shell.execute_reply":"2024-09-27T12:57:55.580144Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def tf_lower_and_split_punct(text):\n    text = tf.strings.lower(text)\n    text = tf.strings.regex_replace(text, \"[^ a-z.?!,¿]\", \"\")\n    text = tf.strings.regex_replace(text, \"[.?!,¿]\", r\" \\0 \")\n    text = tf.strings.strip(text)\n    text = tf.strings.join([\"[SOS]\", text, \"[EOS]\"], separator=\" \")\n    return text\n\nenglish_vectorization =tf.keras.layers.TextVectorization(\n    standardize=tf_lower_and_split_punct,\n    output_mode = 'int',\n    ragged=True,\n    max_tokens=vocab_size,\n    # output_sequence_length = 20\n)\n\nspanish_vectorization =tf.keras.layers.TextVectorization(\n    standardize=tf_lower_and_split_punct,\n    output_mode = 'int',\n    ragged = True,\n    max_tokens=vocab_size,\n    # output_sequence_length=21\n)\nenglish_data = [x[0] for x in train_pairs]\nspanish_data = [x[1] for x in train_pairs]\nenglish_vectorization.adapt(english_data)\nspanish_vectorization.adapt(spanish_data)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-09-27T12:59:35.816355Z","iopub.execute_input":"2024-09-27T12:59:35.816923Z","iopub.status.idle":"2024-09-27T12:59:37.453571Z","shell.execute_reply.started":"2024-09-27T12:59:35.816879Z","shell.execute_reply":"2024-09-27T12:59:37.452500Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# #save the vectorization layers\n# eng_vectorization_config = english_vectorization.get_config()\n# eng_vectorization_config.pop('standardize', None)\nenglish_vocab = english_vectorization.get_vocabulary()\n# with open('eng_vectorization_config.json', 'w', encoding='utf-8') as f:\n#     json.dump(eng_vectorization_config, f)\n    \n# with open('english_vocab.json', 'w', encoding='utf-8') as f:\n#     json.dump(english_vocab, f)\n    \n# spa_vectorization_config = spanish_vectorization.get_config()\n# spa_vectorization_config.pop('standardize', None)\nspanish_vocab = spanish_vectorization.get_vocabulary()\n# with open('spa_vectorization_config.json', 'w', encoding='utf-8') as f:\n#     json.dump(spa_vectorization_config, f)\n    \n# with open('spanish_vocab.json', 'w', encoding='utf-8') as f:\n#     json.dump(spanish_vocab, f)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:00.368918Z","iopub.execute_input":"2024-09-27T13:00:00.369579Z","iopub.status.idle":"2024-09-27T13:00:00.470832Z","shell.execute_reply.started":"2024-09-27T13:00:00.369539Z","shell.execute_reply":"2024-09-27T13:00:00.469492Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"word_to_id = tf.keras.layers.StringLookup(\n    vocabulary = spanish_vocab,\n    mask_token = \"\",\n    oov_token = '[UNK]'\n)\n\nid_to_word = tf.keras.layers.StringLookup(\n    vocabulary = spanish_vocab,\n    mask_token = '',\n    oov_token = '[UNK]',\n    invert = True\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:02.847797Z","iopub.execute_input":"2024-09-27T13:00:02.848584Z","iopub.status.idle":"2024-09-27T13:00:02.993044Z","shell.execute_reply.started":"2024-09-27T13:00:02.848544Z","shell.execute_reply":"2024-09-27T13:00:02.992029Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def tokens_to_text(tokens, id_to_word):\n    words = id_to_word(tokens)\n    result = tf.strings.reduce_join(words, axis=-1, separator=\" \")\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:05.869387Z","iopub.execute_input":"2024-09-27T13:00:05.869784Z","iopub.status.idle":"2024-09-27T13:00:05.874995Z","shell.execute_reply.started":"2024-09-27T13:00:05.869748Z","shell.execute_reply":"2024-09-27T13:00:05.873956Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(english_vocab[:10])\nprint(spanish_vocab[:10])","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:06.248964Z","iopub.execute_input":"2024-09-27T13:00:06.250164Z","iopub.status.idle":"2024-09-27T13:00:06.255555Z","shell.execute_reply.started":"2024-09-27T13:00:06.250110Z","shell.execute_reply":"2024-09-27T13:00:06.254461Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['', '[UNK]', '[SOS]', '[EOS]', '.', 'the', 'i', 'to', 'you', 'tom']\n['', '[UNK]', '[SOS]', '[EOS]', '.', 'de', 'que', 'a', 'no', 'tom']\n","output_type":"stream"}]},{"cell_type":"code","source":"sos_id = word_to_id('[SOS]')\neos_id = word_to_id('[EOS]')","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:08.767929Z","iopub.execute_input":"2024-09-27T13:00:08.768656Z","iopub.status.idle":"2024-09-27T13:00:09.946947Z","shell.execute_reply.started":"2024-09-27T13:00:08.768614Z","shell.execute_reply":"2024-09-27T13:00:09.945925Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def generate_dataset(data, english_vectorization,spanish_vectorization):\n    eng_data = [x[0] for x in data]\n    \n    spa_data = [x[1] for x in data]\n \n    dataset = tf.data.Dataset.from_tensor_slices((eng_data,spa_data)).batch(batch_size = batch_size)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:09.948980Z","iopub.execute_input":"2024-09-27T13:00:09.949685Z","iopub.status.idle":"2024-09-27T13:00:09.955161Z","shell.execute_reply.started":"2024-09-27T13:00:09.949624Z","shell.execute_reply":"2024-09-27T13:00:09.954218Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_dataset = generate_dataset(train_pairs,english_vectorization,spanish_vectorization)\nval_dataset = generate_dataset(val_pairs,english_vectorization,spanish_vectorization)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:12.357837Z","iopub.execute_input":"2024-09-27T13:00:12.358710Z","iopub.status.idle":"2024-09-27T13:00:13.262001Z","shell.execute_reply.started":"2024-09-27T13:00:12.358672Z","shell.execute_reply":"2024-09-27T13:00:13.260987Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(context,target):\n    context = english_vectorization(context)\n    context = context.to_tensor()\n    target = spanish_vectorization(target)\n    targ_in = target[:,:-1].to_tensor()\n    targ_out = target[:,1:].to_tensor()\n    return (context,targ_in),targ_out","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:13.417735Z","iopub.execute_input":"2024-09-27T13:00:13.418351Z","iopub.status.idle":"2024-09-27T13:00:13.423742Z","shell.execute_reply.started":"2024-09-27T13:00:13.418308Z","shell.execute_reply":"2024-09-27T13:00:13.422763Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess_text,tf.data.AUTOTUNE)\nval_dataset = val_dataset.map(preprocess_text,tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:16.156703Z","iopub.execute_input":"2024-09-27T13:00:16.157084Z","iopub.status.idle":"2024-09-27T13:00:16.425509Z","shell.execute_reply.started":"2024-09-27T13:00:16.157052Z","shell.execute_reply":"2024-09-27T13:00:16.424503Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for (x,y),z in train_dataset.take(2):\n    print(x[:2])\n    print(y[:2])\n    print(z[:2])","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:19.877735Z","iopub.execute_input":"2024-09-27T13:00:19.878150Z","iopub.status.idle":"2024-09-27T13:00:19.977768Z","shell.execute_reply.started":"2024-09-27T13:00:19.878112Z","shell.execute_reply":"2024-09-27T13:00:19.976690Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[   2   55  148   21    8   86  488 5127   11    3    0    0    0    0\n     0    0    0    0    0]\n [   2   20    8  121   37    7   35   63   11    3    0    0    0    0\n     0    0    0    0    0]], shape=(2, 19), dtype=int64)\ntf.Tensor(\n[[    2    12   205    61   124   157   729 11280    11     0     0     0\n      0     0     0     0     0]\n [    2    12   204   482    96   602    11     0     0     0     0     0\n      0     0     0     0     0]], shape=(2, 17), dtype=int64)\ntf.Tensor(\n[[   12   205    61   124   157   729 11280    11     3     0     0     0\n      0     0     0     0     0]\n [   12   204   482    96   602    11     3     0     0     0     0     0\n      0     0     0     0     0]], shape=(2, 17), dtype=int64)\ntf.Tensor(\n[[   2    9   40   32   28  334   61   29 1288   20   34 3682  111    4\n     3    0    0    0    0    0    0]\n [   2   17   18   59   25  191    4    3    0    0    0    0    0    0\n     0    0    0    0    0    0    0]], shape=(2, 21), dtype=int64)\ntf.Tensor(\n[[   2    9   36   34  102  381    5   29  590    7   55   13   89    5\n  2168 5142    4    0    0    0]\n [   2   60   51   33   72    4    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0]], shape=(2, 20), dtype=int64)\ntf.Tensor(\n[[   9   36   34  102  381    5   29  590    7   55   13   89    5 2168\n  5142    4    3    0    0    0]\n [  60   51   33   72    4    3    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0]], shape=(2, 20), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Encoder-Decoder Model","metadata":{}},{"cell_type":"code","source":"vocab_size_1 = 12000\nunits_1 = 128","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:22.627603Z","iopub.execute_input":"2024-09-27T13:00:22.627982Z","iopub.status.idle":"2024-09-27T13:00:22.632469Z","shell.execute_reply.started":"2024-09-27T13:00:22.627949Z","shell.execute_reply":"2024-09-27T13:00:22.631380Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### Encoder","metadata":{}},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n    def __init__(self,vocab_size = vocab_size_1,units = units_1):\n        super(Encoder,self).__init__()\n        \n        self.vocab_size = vocab_size\n        self.units =units\n\n        self.embedding = tf.keras.layers.Embedding(input_dim = vocab_size,output_dim = units,input_shape = (None,),mask_zero=True)\n        self.lstm = tf.keras.layers.Bidirectional(merge_mode='sum',layer = tf.keras.layers.LSTM(units,return_sequences= True))\n\n    def call(self,encoder_inputs):\n\n        embedded_output = self.embedding(encoder_inputs)\n        output = self.lstm(embedded_output)\n        return output\n    \n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"vocab_size\": self.vocab_size,\n            \"units\": self.units\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:23.989108Z","iopub.execute_input":"2024-09-27T13:00:23.989834Z","iopub.status.idle":"2024-09-27T13:00:24.000898Z","shell.execute_reply.started":"2024-09-27T13:00:23.989784Z","shell.execute_reply":"2024-09-27T13:00:23.999798Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder(vocab_size,units_1)\n\noutput_1 = encoder(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:24.747530Z","iopub.execute_input":"2024-09-27T13:00:24.747905Z","iopub.status.idle":"2024-09-27T13:00:25.805315Z","shell.execute_reply.started":"2024-09-27T13:00:24.747871Z","shell.execute_reply":"2024-09-27T13:00:25.804458Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"output_1.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:25.806737Z","iopub.execute_input":"2024-09-27T13:00:25.807057Z","iopub.status.idle":"2024-09-27T13:00:25.813079Z","shell.execute_reply.started":"2024-09-27T13:00:25.807024Z","shell.execute_reply":"2024-09-27T13:00:25.812249Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 21, 128])"},"metadata":{}}]},{"cell_type":"markdown","source":"### CrossAttention","metadata":{}},{"cell_type":"code","source":"class CrossAttention(tf.keras.layers.Layer):\n    def __init__(self,units=units_1):\n        super().__init__()\n\n        self.units =units\n\n        self.mha = (tf.keras.layers.MultiHeadAttention(key_dim= units,num_heads=1))\n        self.layernorm = tf.keras.layers.LayerNormalization()\n        self.add = tf.keras.layers.Add()\n\n    def call(self,context,target):\n\n        attn_output = self.mha(query = target,value = context)\n        x = self.add([target,attn_output])\n        x = self.layernorm(x)\n        return x\n    \n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"units\": self.units\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:00:29.987726Z","iopub.execute_input":"2024-09-27T13:00:29.988581Z","iopub.status.idle":"2024-09-27T13:00:29.996054Z","shell.execute_reply.started":"2024-09-27T13:00:29.988542Z","shell.execute_reply":"2024-09-27T13:00:29.995018Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"attention =CrossAttention(units_1)\n# input = tf.keras.layers.Input(shape =(None,))\ntarget = tf.keras.layers.Embedding(vocab_size_1,units_1,input_shape = (None,None),mask_zero=True)(y)\n# input = tf.keras.layers.Input(shape =(None,units_1))\noutput_2 = attention(output_1,target)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:02.107984Z","iopub.execute_input":"2024-09-27T13:01:02.108704Z","iopub.status.idle":"2024-09-27T13:01:02.769013Z","shell.execute_reply.started":"2024-09-27T13:01:02.108662Z","shell.execute_reply":"2024-09-27T13:01:02.768000Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'cross_attention' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"target.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:20.142094Z","iopub.execute_input":"2024-09-27T13:01:20.142501Z","iopub.status.idle":"2024-09-27T13:01:20.151341Z","shell.execute_reply.started":"2024-09-27T13:01:20.142464Z","shell.execute_reply":"2024-09-27T13:01:20.150359Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 20, 128])"},"metadata":{}}]},{"cell_type":"code","source":"output_2.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:21.017067Z","iopub.execute_input":"2024-09-27T13:01:21.018072Z","iopub.status.idle":"2024-09-27T13:01:21.024333Z","shell.execute_reply.started":"2024-09-27T13:01:21.018017Z","shell.execute_reply":"2024-09-27T13:01:21.023283Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 20, 128])"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Decoder","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n    def __init__(self,vocab_size = vocab_size_1,units = units_1):\n        super(Decoder,self).__init__()\n\n        self.vocab_size = vocab_size\n        self.units = units\n\n        self.embedding = tf.keras.layers.Embedding(input_dim = vocab_size,output_dim = units,mask_zero=True)\n        self.pre_attention_rnn = tf.keras.layers.LSTM(units,return_sequences = True,return_state = True)\n        self.attention = CrossAttention(units)\n        self.post_attention_rnn = tf.keras.layers.LSTM(units = units,return_sequences=True)\n        self.dense = tf.keras.layers.Dense(vocab_size,activation = tf.nn.log_softmax)\n\n    def call(self,context,target,state = None,return_state = False):\n\n        embedding_output = self.embedding(target)\n        x,state_h,state_c = self.pre_attention_rnn(embedding_output,initial_state=state)\n        x = self.attention(context,x)\n        x = self.post_attention_rnn(x)\n        logits = self.dense(x)\n\n        if return_state:\n            return logits,[state_h,state_c]\n\n        return logits\n\n        \n    \n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"vocab_size\": self.vocab_size,\n            \"units\": self.units\n        })\n        return config\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:22.949530Z","iopub.execute_input":"2024-09-27T13:01:22.949919Z","iopub.status.idle":"2024-09-27T13:01:22.960038Z","shell.execute_reply.started":"2024-09-27T13:01:22.949882Z","shell.execute_reply":"2024-09-27T13:01:22.959109Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"decoder = Decoder(vocab_size,units_1)\noutput= decoder(output_1,y)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:23.797512Z","iopub.execute_input":"2024-09-27T13:01:23.797924Z","iopub.status.idle":"2024-09-27T13:01:24.208499Z","shell.execute_reply.started":"2024-09-27T13:01:23.797890Z","shell.execute_reply":"2024-09-27T13:01:24.207521Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'cross_attention_1' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'decoder' (of type Decoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"output.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:26.027518Z","iopub.execute_input":"2024-09-27T13:01:26.027917Z","iopub.status.idle":"2024-09-27T13:01:26.034002Z","shell.execute_reply.started":"2024-09-27T13:01:26.027882Z","shell.execute_reply":"2024-09-27T13:01:26.033072Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 20, 12000])"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#### Translator Model","metadata":{}},{"cell_type":"code","source":"class Translator(tf.keras.Model):\n    def __init__(self,vocab_size =vocab_size_1,units = units_1):\n        super().__init__()\n        self.encoder = Encoder(vocab_size,units)\n        self.decoder = Decoder(vocab_size,units)\n\n    def call(self,inputs):\n        context,target = inputs\n        encoder_output = self.encoder(context)\n        logits = self.decoder(encoder_output,target)\n\n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:33.815818Z","iopub.execute_input":"2024-09-27T13:01:33.816715Z","iopub.status.idle":"2024-09-27T13:01:33.822645Z","shell.execute_reply.started":"2024-09-27T13:01:33.816672Z","shell.execute_reply":"2024-09-27T13:01:33.821677Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"translator = Translator(vocab_size_1,units_1)\noutputs = translator((x,y))\noutputs.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:35.975506Z","iopub.execute_input":"2024-09-27T13:01:35.975868Z","iopub.status.idle":"2024-09-27T13:01:36.928065Z","shell.execute_reply.started":"2024-09-27T13:01:35.975836Z","shell.execute_reply":"2024-09-27T13:01:36.927134Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'cross_attention_2' (of type CrossAttention) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:877: UserWarning: Layer 'decoder_1' (of type Decoder) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"TensorShape([64, 20, 12000])"},"metadata":{}}]},{"cell_type":"code","source":"def compile_and_train(model,epochs =5,steps_per_epoch = 500):\n    model.compile(optimizer = 'adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction = 'none'),\n                  metrics = ['accuracy'])\n\n    history  = model.fit(\n        train_dataset.repeat(),\n        epochs = epochs,\n        steps_per_epoch = steps_per_epoch,\n        validation_data = val_dataset,\n        validation_steps = 50,\n        callbacks = [tf.keras.callbacks.EarlyStopping(patience=3)]\n    )\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:01:38.847678Z","iopub.execute_input":"2024-09-27T13:01:38.848326Z","iopub.status.idle":"2024-09-27T13:01:38.854590Z","shell.execute_reply.started":"2024-09-27T13:01:38.848285Z","shell.execute_reply":"2024-09-27T13:01:38.853636Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"trained_translator,history = compile_and_train(translator,epochs =10)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:07:41.065103Z","iopub.execute_input":"2024-09-27T13:07:41.065822Z","iopub.status.idle":"2024-09-27T13:11:10.454812Z","shell.execute_reply.started":"2024-09-27T13:07:41.065779Z","shell.execute_reply":"2024-09-27T13:11:10.453980Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 42ms/step - accuracy: 0.8472 - loss: 0.8551 - val_accuracy: 0.8401 - val_loss: 0.9363\nEpoch 2/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8507 - loss: 0.8628 - val_accuracy: 0.8408 - val_loss: 0.9057\nEpoch 3/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8497 - loss: 0.8488 - val_accuracy: 0.8527 - val_loss: 0.8228\nEpoch 4/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8652 - loss: 0.6929 - val_accuracy: 0.8554 - val_loss: 0.8160\nEpoch 5/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8678 - loss: 0.7013 - val_accuracy: 0.8581 - val_loss: 0.7685\nEpoch 6/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8686 - loss: 0.6876 - val_accuracy: 0.8632 - val_loss: 0.7499\nEpoch 7/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - accuracy: 0.8803 - loss: 0.5868 - val_accuracy: 0.8617 - val_loss: 0.7640\nEpoch 8/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - accuracy: 0.8794 - loss: 0.6058 - val_accuracy: 0.8667 - val_loss: 0.7176\nEpoch 9/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8803 - loss: 0.5934 - val_accuracy: 0.8653 - val_loss: 0.7229\nEpoch 10/10\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 41ms/step - accuracy: 0.8906 - loss: 0.5160 - val_accuracy: 0.8646 - val_loss: 0.7293\n","output_type":"stream"}]},{"cell_type":"code","source":"trained_translator.evaluate(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:11:31.054023Z","iopub.execute_input":"2024-09-27T13:11:31.054966Z","iopub.status.idle":"2024-09-27T13:11:39.329371Z","shell.execute_reply.started":"2024-09-27T13:11:31.054923Z","shell.execute_reply":"2024-09-27T13:11:39.328443Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"\u001b[1m372/372\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.8675 - loss: 0.7141\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[0.7125270366668701, 0.8681114315986633]"},"metadata":{}}]},{"cell_type":"code","source":"def generate_next_token(decoder,context,next_token,state,beam_width):\n    \n    logits,state = decoder(context,next_token,state,return_state = True)\n\n    logits = logits[:,-1,:]\n\n    next_logits , next_tokens = tf.nn.top_k(logits,k = beam_width)\n\n    next_logits = tf.squeeze(next_logits).numpy()\n\n    next_tokens = tf.squeeze(next_tokens).numpy()\n    if beam_width == 1:\n        return [next_tokens],state,[next_logits]\n\n    return next_tokens,state,next_logits","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:11:41.582369Z","iopub.execute_input":"2024-09-27T13:11:41.583294Z","iopub.status.idle":"2024-09-27T13:11:41.589382Z","shell.execute_reply.started":"2024-09-27T13:11:41.583251Z","shell.execute_reply":"2024-09-27T13:11:41.588491Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def translate(model,text,max_length = 30,beam_width= 1,english_vectorizer = english_vectorization):\n\n    text = tf.convert_to_tensor(text)[tf.newaxis]\n\n    context = english_vectorizer(text).to_tensor()\n\n    context = model.encoder(context)\n    state = [tf.zeros((1,units_1)),tf.zeros((1,units_1))]\n\n    end_token = tf.fill((1,1),eos_id)\n\n    done  = False\n\n    sequences = [[[sos_id.numpy()],0.0,state]]\n\n    final_sequences = []\n    k = beam_width\n    for i in range(max_length):\n\n        if len(final_sequences)<k:\n\n            if len(sequences)>k:\n                sequences.sort(key = lambda x: x[1],reverse = True)\n                sequences = sequences[:k]\n            \n            pre_sequences = []\n            for i in range(len(sequences)):\n\n                cur_sequence = sequences[i]\n\n                cur_token = tf.cast(tf.fill((1,1),cur_sequence[0][-1]),end_token.dtype)\n\n                cur_state = cur_sequence[2]\n\n                if cur_token == end_token:\n                    final_sequences.append(copy.deepcopy(cur_sequence))\n                    continue\n\n                next_tokens,state,next_logits = generate_next_token(decoder = model.decoder,\n                                                                        context = context,\n                                                                        next_token = cur_token,\n                                                                        state = cur_state,\n                                                                        beam_width = k)\n                \n    \n                my_sequences = [copy.deepcopy(cur_sequence) for x in range(k)]\n\n                for i in range(len(my_sequences)):\n                    my_sequences[i][0].append(next_tokens[i])\n\n                    my_sequences[i][1]+=next_logits[i]\n\n                    my_sequences[i][2] = state\n\n                pre_sequences+=my_sequences\n                \n\n            sequences = pre_sequences\n\n    def cleaning(list_sequences):\n        my_list = []\n        list_sequences.sort(key = lambda x: x[1],reverse = True)\n        \n        if len(list_sequences)>k:\n                list_sequences = list_sequences[:k]\n        for sequence in list_sequences:\n            my_tokens = sequence[0]\n            score = sequence[1]\n            translation = tokens_to_text(my_tokens,id_to_word)\n            translation = translation.numpy().decode()\n            my_list.append([translation,f'score: {round(score,3)}'])\n        return my_list\n    return cleaning(final_sequences)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:11:44.062548Z","iopub.execute_input":"2024-09-27T13:11:44.063552Z","iopub.status.idle":"2024-09-27T13:11:44.078447Z","shell.execute_reply.started":"2024-09-27T13:11:44.063487Z","shell.execute_reply":"2024-09-27T13:11:44.077521Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"eng_data = [x[0] for x in data]\nspa_data = [x[1] for x in data]","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:12:27.984597Z","iopub.execute_input":"2024-09-27T13:12:27.985008Z","iopub.status.idle":"2024-09-27T13:12:28.028242Z","shell.execute_reply.started":"2024-09-27T13:12:27.984970Z","shell.execute_reply":"2024-09-27T13:12:28.027451Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"p = 12345\nprint(eng_data[p])\nprint(spa_data[p])","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:14:08.904628Z","iopub.execute_input":"2024-09-27T13:14:08.905423Z","iopub.status.idle":"2024-09-27T13:14:08.910225Z","shell.execute_reply.started":"2024-09-27T13:14:08.905379Z","shell.execute_reply":"2024-09-27T13:14:08.909295Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"It didn't take Tom long to realize he wasn't welcome there.\n No le tomó mucho a Tom darse cuenta de que no era bienvenido allí. \n","output_type":"stream"}]},{"cell_type":"code","source":"translate(trained_translator,eng_data[p],beam_width=3)","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:14:10.682020Z","iopub.execute_input":"2024-09-27T13:14:10.682837Z","iopub.status.idle":"2024-09-27T13:14:11.774114Z","shell.execute_reply.started":"2024-09-27T13:14:10.682799Z","shell.execute_reply":"2024-09-27T13:14:11.773072Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"[['[SOS] no escrib a tom mucho suficiente cuenta que no era bienvenido all . [EOS]',\n  'score: -13.274'],\n ['[SOS] no escrib a tom mucho suficiente cuenta que no fue bienvenido all . [EOS]',\n  'score: -14.214'],\n ['[SOS] no escrib a tom mucho suficiente cuenta que no era bienvenido ah . [EOS]',\n  'score: -14.807']]"},"metadata":{}}]},{"cell_type":"code","source":"trained_translator.save_weights('english_to_spanis.weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-27T13:16:30.994066Z","iopub.execute_input":"2024-09-27T13:16:30.994501Z","iopub.status.idle":"2024-09-27T13:16:31.176122Z","shell.execute_reply.started":"2024-09-27T13:16:30.994465Z","shell.execute_reply":"2024-09-27T13:16:31.175072Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load and set the English vocabulary\nwith open('english_vocab.json') as json_file:\n    english_vocab = json.load(json_file)\n    english_vectorization.set_vocabulary(english_vocab)\n\n# Load and set the Spanish vocabulary\nwith open('spanish_vocab.json') as json_file:\n    spanish_vocab = json.load(json_file)\n    spanish_vectorization.set_vocabulary(spanish_vocab)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
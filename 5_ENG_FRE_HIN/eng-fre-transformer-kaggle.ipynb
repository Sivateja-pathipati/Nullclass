{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9498982,"sourceType":"datasetVersion","datasetId":5780605}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport random\nimport string\nimport json\nimport re\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:31.418507Z","iopub.execute_input":"2024-09-28T11:12:31.418808Z","iopub.status.idle":"2024-09-28T11:12:50.326740Z","shell.execute_reply.started":"2024-09-28T11:12:31.418772Z","shell.execute_reply":"2024-09-28T11:12:50.325753Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/english-french-google-translation/english_french.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"path = \"/kaggle/input/english-french-google-translation/english_french.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:50.328436Z","iopub.execute_input":"2024-09-28T11:12:50.329439Z","iopub.status.idle":"2024-09-28T11:12:50.333402Z","shell.execute_reply.started":"2024-09-28T11:12:50.329389Z","shell.execute_reply":"2024-09-28T11:12:50.332525Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/english-french-google-translation/english_french.csv',index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:51.924123Z","iopub.execute_input":"2024-09-28T11:12:51.924481Z","iopub.status.idle":"2024-09-28T11:12:52.273267Z","shell.execute_reply.started":"2024-09-28T11:12:51.924448Z","shell.execute_reply":"2024-09-28T11:12:52.272457Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:53.109155Z","iopub.execute_input":"2024-09-28T11:12:53.109533Z","iopub.status.idle":"2024-09-28T11:12:53.125305Z","shell.execute_reply.started":"2024-09-28T11:12:53.109497Z","shell.execute_reply":"2024-09-28T11:12:53.124283Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                             English  \\\n0                         We do not have any choice.   \n1                            I like that it is soft.   \n2                           Was there an earthquake?   \n3                               They say he is sick.   \n4  You should always wear a seat belt when you ar...   \n\n                                              French  \n0                         Nous n'avons pas le choix.  \n1                           J'aime que ce soit doux.  \n2              Y a-t-il eu un tremblement de terre ?  \n3                     Elles disent qu'il est malade.  \n4  On devrait toujours mettre une ceinture lorsqu...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>We do not have any choice.</td>\n      <td>Nous n'avons pas le choix.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I like that it is soft.</td>\n      <td>J'aime que ce soit doux.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Was there an earthquake?</td>\n      <td>Y a-t-il eu un tremblement de terre ?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>They say he is sick.</td>\n      <td>Elles disent qu'il est malade.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You should always wear a seat belt when you ar...</td>\n      <td>On devrait toujours mettre une ceinture lorsqu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:53.879139Z","iopub.execute_input":"2024-09-28T11:12:53.879750Z","iopub.status.idle":"2024-09-28T11:12:53.909363Z","shell.execute_reply.started":"2024-09-28T11:12:53.879712Z","shell.execute_reply":"2024-09-28T11:12:53.908478Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"English    False\nFrench     False\ndtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"text_pairs =list(zip(df['English'],df['French']))\nrandom.seed(42)\nrandom.shuffle(text_pairs)\nprint(text_pairs[:5])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:54.469147Z","iopub.execute_input":"2024-09-28T11:12:54.469541Z","iopub.status.idle":"2024-09-28T11:12:54.624100Z","shell.execute_reply.started":"2024-09-28T11:12:54.469506Z","shell.execute_reply":"2024-09-28T11:12:54.623145Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[('I did not want to give up.', 'Je ne voulais pas abandonner.'), ('What is happening?', \"Qu'est-ce qui se passe\\u202f?\"), ('Protesters tried to disrupt the meeting.', 'Les protestataires tentèrent de perturber la réunion.'), ('You could not have picked a better spot.', \"Vous n'auriez pas pu choisir un meilleur endroit.\"), ('That looks like it hurts.', 'On dirait que ça fait mal.')]\n","output_type":"stream"}]},{"cell_type":"code","source":"num_val_samples = int(0.1 * len(text_pairs))\nnum_train_samples = len(text_pairs) -  2*num_val_samples\ntrain_pairs = text_pairs[:num_train_samples]\nval_pairs = text_pairs[num_train_samples:num_train_samples+num_val_samples]\ntest_pairs = text_pairs[num_train_samples+num_val_samples:]\n\nprint(f\"{len(text_pairs)} total pairs\")\nprint(f\"{len(train_pairs)} training pairs\")\nprint(f\"{len(val_pairs)} validation pairs\")\nprint(f'{len(test_pairs)} test pairs')","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:55.003986Z","iopub.execute_input":"2024-09-28T11:12:55.004805Z","iopub.status.idle":"2024-09-28T11:12:55.012740Z","shell.execute_reply.started":"2024-09-28T11:12:55.004767Z","shell.execute_reply":"2024-09-28T11:12:55.011801Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"108742 total pairs\n86994 training pairs\n10874 validation pairs\n10874 test pairs\n","output_type":"stream"}]},{"cell_type":"code","source":"list1 = list(df['English'])\nlist1 = [word.strip().strip('!').strip('.').strip(',').strip('?').lower() for sentence in list1 for word in sentence.split(' ') if len(word)]\n\nprint('approx english vocab:',len(set(list1)))\n\nlist2 = list(df['French'])\nlist2 = [word.strip('!').strip('.').strip(',').strip('?') for sentence in list2 for word in sentence.split(' ')]\nprint('approx french vocab:',len(set(list2)))","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:55.459036Z","iopub.execute_input":"2024-09-28T11:12:55.459490Z","iopub.status.idle":"2024-09-28T11:12:56.197724Z","shell.execute_reply.started":"2024-09-28T11:12:55.459449Z","shell.execute_reply":"2024-09-28T11:12:56.196784Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"approx english vocab: 16443\napprox french vocab: 29092\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(10,20):\n    print(list1[i*10:i*10+10])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:56.199463Z","iopub.execute_input":"2024-09-28T11:12:56.199793Z","iopub.status.idle":"2024-09-28T11:12:56.204882Z","shell.execute_reply.started":"2024-09-28T11:12:56.199759Z","shell.execute_reply":"2024-09-28T11:12:56.203972Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['a', 'relatively', 'safe', 'neighborhood', 'tom', 'and', 'mary', 'were', 'on', 'the']\n['same', 'wavelength', 'kripananda', 'this', 'place', 'is', 'boring', 'what', 'is', 'your']\n['favorite', 'toothpaste', 'qualitised', 'postulated', 'complement', 'why', 'do', 'not', 'you', 'tell']\n['me', 'what', 'you', 'want', 'to', 'hear', 'someone', 'cleaned', 'my', 'room']\n['while', 'i', 'was', 'gone', 'he', 'lived', 'alone', 'in', 'the', 'forest']\n['i', 'feel', 'bad', 'that', 'i', 'have', 'not', 'paid', 'you', 'yet']\n['are', 'you', 'already', 'married', 'i', 'am', 'going', 'to', 'drive', 'myself']\n['it', 'has', 'a', 'leak', 'whether', 'shakespeare', 'wrote', 'this', 'poem', 'or']\n['not', 'will', 'probably', 'remain', 'a', 'mystery', 'you', 'are', 'safe', 'here']\n['i', 'prefer', 'to', 'travel', 'alone', 'classifies', 'we', 'appreciate', 'your', 'kind']\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(10,20):\n    print(list2[i*10:i*10+10])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:56.343472Z","iopub.execute_input":"2024-09-28T11:12:56.343793Z","iopub.status.idle":"2024-09-28T11:12:56.348949Z","shell.execute_reply.started":"2024-09-28T11:12:56.343761Z","shell.execute_reply":"2024-09-28T11:12:56.348083Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['vous', 'demander', 'une', 'dernière', 'faveur', 'Je', 'vis', 'dans', 'un', 'quartier']\n['relativement', 'sûr', 'Tom', 'et', 'Marie', 'étaient', 'sur', 'la', 'même', 'longueur']\n['d’onde', 'Kripananda', 'Cet', 'endroit', 'est', 'ennuyeux', 'Quel', 'est', 'votre', 'dentifrice']\n['préféré\\u202f', 'qualifié', 'postulé', 'complément', 'Pourquoi', 'ne', 'me', 'dites-vous', 'pas', 'ce']\n['que', 'vous', 'voulez', 'entendre', '', \"Quelqu'un\", 'nettoya', 'ma', 'chambre', 'pendant']\n['que', \"j'étais\", 'parti', 'Il', 'a', 'vécu', 'seul', 'dans', 'la', 'forêt']\n['Je', 'me', 'sens', 'mal', 'de', 'ne', 'pas', 'encore', \"t'avoir\", 'payé']\n['Êtes-vous', 'déjà', 'mariée', '', 'Je', 'vais', 'conduire', 'par', 'mes', 'propres']\n['moyens', 'Elle', 'fuit', 'Si', 'Shakespeare', 'a', 'écrit', 'ce', 'poème', 'ou']\n['pas', 'restera', 'probablement', 'une', 'énigme', 'Vous', 'êtes', 'en', 'sécurité', 'ici']\n","output_type":"stream"}]},{"cell_type":"code","source":"def tf_lower_and_split_punct(text):\n    text = tf.strings.lower(text)\n    text = tf.strings.regex_replace(text, \"[^ a-z.?!,¿]\", \"\")\n    text = tf.strings.regex_replace(text, \"[.?!,¿]\", r\" \\0 \")\n    text = tf.strings.strip(text)\n    text = tf.strings.join([\"[SOS]\", text, \"[EOS]\"], separator=\" \")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:56.908829Z","iopub.execute_input":"2024-09-28T11:12:56.909220Z","iopub.status.idle":"2024-09-28T11:12:56.914746Z","shell.execute_reply.started":"2024-09-28T11:12:56.909184Z","shell.execute_reply":"2024-09-28T11:12:56.913922Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#some extra characters in french that are not in english\nmy_extra_list = ['À', 'Â', 'Ç', 'É', 'Ê', 'Ô', 'à', 'á', 'â', 'ç', 'è', 'é', 'ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'ü', 'ō', 'œ']\nmy_extra_list = [i.lower() for i in my_extra_list]\nmy_extra_list = list(set(my_extra_list))\n\nmy_extra_string = ''.join(my_extra_list)\nprint(my_extra_string.lower())","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:57.429119Z","iopub.execute_input":"2024-09-28T11:12:57.429886Z","iopub.status.idle":"2024-09-28T11:12:57.435972Z","shell.execute_reply.started":"2024-09-28T11:12:57.429846Z","shell.execute_reply":"2024-09-28T11:12:57.434940Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"àōœâîûüêëùôáçïéè\n","output_type":"stream"}]},{"cell_type":"code","source":"def tf_lower_and_split_punct_2(text):\n    text = tf.strings.lower(text)\n    text = tf.strings.regex_replace(text, \"[^ a-zçèœêâôïûùüàáōëîé.?!,¿]\", \"\")\n    text = tf.strings.regex_replace(text, \"[.?!,¿]\", r\" \\0 \")\n    text = tf.strings.strip(text)\n    text = tf.strings.join([\"[SOS]\", text, \"[EOS]\"], separator=\" \")\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:58.554371Z","iopub.execute_input":"2024-09-28T11:12:58.554746Z","iopub.status.idle":"2024-09-28T11:12:58.560492Z","shell.execute_reply.started":"2024-09-28T11:12:58.554709Z","shell.execute_reply":"2024-09-28T11:12:58.559565Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vocab_size = 15000\nsequence_length = 20\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:59.063936Z","iopub.execute_input":"2024-09-28T11:12:59.064298Z","iopub.status.idle":"2024-09-28T11:12:59.068458Z","shell.execute_reply.started":"2024-09-28T11:12:59.064266Z","shell.execute_reply":"2024-09-28T11:12:59.067584Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# vectorization\nenglish_vectorization = tf.keras.layers.TextVectorization(\n    max_tokens = vocab_size,\n    output_mode = \"int\",\n    output_sequence_length = sequence_length,\n    standardize=tf_lower_and_split_punct\n)\n\nfrench_vectorization = tf.keras.layers.TextVectorization(\n    max_tokens = vocab_size,\n    output_mode = \"int\",\n    output_sequence_length = sequence_length+1,\n    standardize=tf_lower_and_split_punct_2\n)\n\ntrain_eng_texts = [pair[0] for pair in train_pairs]\ntrain_fre_texts = [pair[1] for pair in train_pairs]\n\nenglish_vectorization.adapt(train_eng_texts)\nfrench_vectorization.adapt(train_fre_texts)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:12:59.928953Z","iopub.execute_input":"2024-09-28T11:12:59.929328Z","iopub.status.idle":"2024-09-28T11:13:01.750601Z","shell.execute_reply.started":"2024-09-28T11:12:59.929292Z","shell.execute_reply":"2024-09-28T11:13:01.749766Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#save the vectorization layers\n\nenglish_vocab = english_vectorization.get_vocabulary()\n    \nwith open('english_vocab.json', 'w', encoding='utf-8') as f:\n    json.dump(english_vocab, f)\n    \nfrench_vocab = french_vectorization.get_vocabulary()\n    \nwith open('french_vocab.json', 'w', encoding='utf-8') as f:\n    json.dump(french_vocab, f)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:01.752340Z","iopub.execute_input":"2024-09-28T11:13:01.752671Z","iopub.status.idle":"2024-09-28T11:13:01.892510Z","shell.execute_reply.started":"2024-09-28T11:13:01.752638Z","shell.execute_reply":"2024-09-28T11:13:01.891783Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(len(english_vocab))\nprint(english_vocab[:20])\nprint(french_vocab[:20])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:01.893452Z","iopub.execute_input":"2024-09-28T11:13:01.893747Z","iopub.status.idle":"2024-09-28T11:13:01.898871Z","shell.execute_reply.started":"2024-09-28T11:13:01.893715Z","shell.execute_reply":"2024-09-28T11:13:01.897950Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"15000\n['', '[UNK]', '[SOS]', '[EOS]', '.', 'i', 'you', 'to', 'the', 'is', '?', 'not', 'a', 'do', 'that', 'are', 'it', 'have', 'tom', 'he']\n['', '[UNK]', '[SOS]', '[EOS]', '.', 'je', 'de', 'pas', '?', 'que', 'ne', 'à', 'la', 'le', 'vous', 'il', 'tom', 'est', ',', 'a']\n","output_type":"stream"}]},{"cell_type":"code","source":"list1 = [x for x in english_vocab if len(x)==10]\nlen(list1)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:02.628803Z","iopub.execute_input":"2024-09-28T11:13:02.629501Z","iopub.status.idle":"2024-09-28T11:13:02.656590Z","shell.execute_reply.started":"2024-09-28T11:13:02.629459Z","shell.execute_reply":"2024-09-28T11:13:02.655566Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"5606"},"metadata":{}}]},{"cell_type":"code","source":"def format_dataset(eng, spa):\n    eng = english_vectorization(eng)\n    fre = french_vectorization(spa)\n    return (\n        {\n            \"encoder_inputs\": eng,\n            \"decoder_inputs\": fre[:, :-1],\n        },\n        fre[:, 1:],\n    )\n    \ndef make_dataset(pairs):\n    eng_texts, fre_texts = zip(*pairs)\n    eng_texts = list(eng_texts)\n    fre_texts = list(fre_texts)\n    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, fre_texts))\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.map(format_dataset)\n    return dataset.cache().shuffle(2048).prefetch(16)\n\ntrain_ds = make_dataset(train_pairs)\nval_ds = make_dataset(val_pairs)\ntest_ds = make_dataset(test_pairs)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:04.309215Z","iopub.execute_input":"2024-09-28T11:13:04.309571Z","iopub.status.idle":"2024-09-28T11:13:05.808870Z","shell.execute_reply.started":"2024-09-28T11:13:04.309532Z","shell.execute_reply":"2024-09-28T11:13:05.807853Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for inp,tar in train_ds.take(1):\n    print(inp['encoder_inputs'][:2])\n    print(inp['decoder_inputs'][:2])\n    print(tar[:2])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:22.229549Z","iopub.execute_input":"2024-09-28T11:13:22.229946Z","iopub.status.idle":"2024-09-28T11:13:22.278908Z","shell.execute_reply.started":"2024-09-28T11:13:22.229910Z","shell.execute_reply":"2024-09-28T11:13:22.277959Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[   2   32    6  332   22  153   10    3    0    0    0    0    0    0\n     0    0    0    0    0    0]\n [   2    8 8067 6368   62 1474 2283  104    8 4598 6368    4    3    0\n     0    0    0    0    0    0]], shape=(2, 20), dtype=int64)\ntf.Tensor(\n[[    2   122   504    20   175     8     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0]\n [    2  7576 11605    17  2661 14986    38  1655     9  7576 11591     4\n      3     0     0     0     0     0     0     0]], shape=(2, 20), dtype=int64)\ntf.Tensor(\n[[  122   504    20   175     8     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0]\n [ 7576 11605    17  2661 14986    38  1655     9  7576 11591     4     3\n      0     0     0     0     0     0     0     0]], shape=(2, 20), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = 15000\nunits_1 = 128","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:24.644519Z","iopub.execute_input":"2024-09-28T11:13:24.644939Z","iopub.status.idle":"2024-09-28T11:13:24.649448Z","shell.execute_reply.started":"2024-09-28T11:13:24.644890Z","shell.execute_reply":"2024-09-28T11:13:24.648500Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class TransformerEncoder(tf.keras.layers.Layer):\n    def __init__(self,embed_dim,dense_dim,num_heads,**kwargs):\n        super().__init__(**kwargs)\n\n        self.num_heads = num_heads\n        self.embed_dim = embed_dim\n        self.dense_dim = dense_dim\n\n        self.mha = tf.keras.layers.MultiHeadAttention(\n            num_heads=num_heads,\n            key_dim = embed_dim\n        )\n        self.dense_proj = tf.keras.Sequential(\n            [\n                tf.keras.layers.Dense(dense_dim,activation = 'relu'),\n                tf.keras.layers.Dense(embed_dim)\n            ]\n        )\n        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self,inputs,mask = None):\n        if mask is not None:\n            padding_mask = tf.cast(mask[:,None,:],dtype = tf.int32)\n        else:\n            padding_mask = None\n        attention_output = self.mha(\n            query = inputs,\n            value = inputs,\n            key = inputs,\n            attention_mask = padding_mask\n        )\n        proj_input = self.layernorm_1(attention_output+inputs)\n        proj_output = self.dense_proj(proj_input)\n        output = self.layernorm_2(proj_input + proj_output)\n        return output\n    \n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            'embed_dim':self.embed_dim,\n            'dense_dim':self.dense_dim,\n            'num_heads': self.num_heads,\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:26.276189Z","iopub.execute_input":"2024-09-28T11:13:26.276582Z","iopub.status.idle":"2024-09-28T11:13:26.287475Z","shell.execute_reply.started":"2024-09-28T11:13:26.276543Z","shell.execute_reply":"2024-09-28T11:13:26.286573Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class PositionalEmbedding(tf.keras.layers.Layer):\n    def __init__(self,sequence_length,vocab_size,embed_dim,**kwargs):\n        super().__init__(**kwargs)\n\n        self.embed_dim = embed_dim\n        self.vocab_size = vocab_size\n        self.sequence_length = sequence_length\n        \n        self.token_embeddings = tf.keras.layers.Embedding(\n            input_dim = vocab_size,\n            output_dim  = embed_dim\n        )\n\n        self.position_embeddings = tf.keras.layers.Embedding(\n            input_dim = sequence_length,\n            output_dim = embed_dim\n        )\n\n    def call(self,inputs):\n        length = tf.shape(inputs)[-1]\n        positions = tf.range(start = 0,limit = length,delta =1)\n        embeded_tokens = self.token_embeddings(inputs)\n        embeded_position = self.position_embeddings(positions)\n        return embeded_tokens + embeded_position\n    \n    def compute_mask(self,inputs,mask =None):\n        if mask is not None:\n            return tf.not_equal(inputs,0)\n        else:\n            return None\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            'vocab_size': self.vocab_size,\n            'sequence_length': self.sequence_length,\n            'embed_dim': self.embed_dim,\n        })\n        return config","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:26.933940Z","iopub.execute_input":"2024-09-28T11:13:26.934321Z","iopub.status.idle":"2024-09-28T11:13:26.944179Z","shell.execute_reply.started":"2024-09-28T11:13:26.934285Z","shell.execute_reply":"2024-09-28T11:13:26.943223Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"class TransformerDecoder(tf.keras.layers.Layer):\n    def __init__(self,embed_dim,latent_dim,num_heads,**kwargs):\n        super().__init__(**kwargs)\n\n        self.embed_dim = embed_dim\n        self.latent_dim = latent_dim\n        self.num_heads = num_heads\n\n        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,key_dim=embed_dim)\n        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads = num_heads,key_dim=embed_dim)\n\n        self.dense_proj = tf.keras.Sequential(\n            [\n                tf.keras.layers.Dense(latent_dim,activation = 'relu'),\n                tf.keras.layers.Dense(embed_dim),\n            ]\n        )\n        self.layernorm_1 = tf.keras.layers.LayerNormalization()\n        self.layernorm_2 = tf.keras.layers.LayerNormalization()\n        self.layernorm_3 = tf.keras.layers.LayerNormalization()\n        self.supports_masking = True\n\n    def call(self,inputs,encoder_outputs,mask=None):\n        casual_mask = self.get_casual_attention_mask(inputs)\n        if mask is not None:\n            padding_mask = tf.cast(mask[:,None,:],dtype = tf.int32)\n            padding_mask = tf.minimum(padding_mask,casual_mask)\n        else:\n            padding_mask = None\n\n        attention_output1 = self.mha1(\n            query = inputs,\n            value = inputs,\n            key = inputs,\n            attention_mask = casual_mask\n        )\n\n        out_1 = self.layernorm_1(inputs + attention_output1)\n\n        attention_output2 = self.mha2(\n            query = out_1,\n            value = encoder_outputs,\n            key = encoder_outputs,\n            attention_mask = padding_mask,\n        )\n\n        out_2 = self.layernorm_2(out_1 + attention_output2)\n        proj_output = self.dense_proj(out_2)\n        output = self.layernorm_3(proj_output + out_2)\n\n        return output\n    \n    def get_casual_attention_mask(self,inputs):\n        input_shape = tf.shape(inputs)\n        batch_size,sequence_length = input_shape[0],input_shape[1]\n        i = tf.range(sequence_length)[:,None]\n        j = tf.range(sequence_length)\n        mask = tf.cast(i>=j,tf.int32)\n        mask = tf.reshape(mask,(1,input_shape[1],input_shape[1]))\n        mult = tf.concat(\n            [\n                tf.expand_dims(batch_size,-1),\n                tf.convert_to_tensor([1,1]),\n            ],\n            axis =0,\n        )\n        return tf.tile(mask,mult)\n    \n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            'embed_dim': self.embed_dim,\n            'latent_dim': self.latent_dim,\n            'num_heads': self.num_heads\n        })\n        return config\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:27.320407Z","iopub.execute_input":"2024-09-28T11:13:27.320813Z","iopub.status.idle":"2024-09-28T11:13:27.336051Z","shell.execute_reply.started":"2024-09-28T11:13:27.320766Z","shell.execute_reply":"2024-09-28T11:13:27.335103Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# define emmbedding dimensions, latent dimensions, and number of heads\nembed_dim = 100\nlatent_dim = 256\nnum_heads = 2\n\n#Encoder\nencoder_inputs = tf.keras.Input(shape = (None,), dtype = \"int64\", name = \"encoder_inputs\")\n\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n\nencoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n\nencoder = tf.keras.Model(encoder_inputs, encoder_outputs, name = \"encoder\")\n\n#Decoder\ndecoder_inputs = tf.keras.Input(shape = (None,), dtype = \"int64\", name = \"decoder_inputs\")\nencoder_seq_inputs = tf.keras.Input(shape = (None, embed_dim), name = \"encoder_seq_inputs\")\n\nx = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n\nx = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoder_seq_inputs)\n\nx = tf.keras.layers.Dropout(0.5)(x)\n\ndecoder_outputs = tf.keras.layers.Dense(vocab_size, activation = tf.nn.log_softmax)(x)\n\ndecoder = tf.keras.Model([decoder_inputs, encoder_seq_inputs], decoder_outputs, name = \"decoder\")\n\n# Define the final model\ndecoder_outputs = decoder([decoder_inputs, encoder_outputs])\n\ntransformer = tf.keras.Model(\n    [encoder_inputs, decoder_inputs], decoder_outputs, name = \"transformer\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:38.023857Z","iopub.execute_input":"2024-09-28T11:13:38.024617Z","iopub.status.idle":"2024-09-28T11:13:38.690029Z","shell.execute_reply.started":"2024-09-28T11:13:38.024579Z","shell.execute_reply":"2024-09-28T11:13:38.689026Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nlosses = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\ntransformer.summary()\n\ntransformer.compile(\n    \"adam\", loss = losses, metrics = [\"accuracy\"]\n)\n# transformer.fit(train_ds, epochs = epochs, validation_data = val_ds)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:39.493926Z","iopub.execute_input":"2024-09-28T11:13:39.494749Z","iopub.status.idle":"2024-09-28T11:13:39.528060Z","shell.execute_reply.started":"2024-09-28T11:13:39.494708Z","shell.execute_reply":"2024-09-28T11:13:39.527034Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"transformer\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │  \u001b[38;5;34m1,502,000\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mPositionalEmbeddi…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │    \u001b[38;5;34m132,656\u001b[0m │ positional_embed… │\n│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m3,230,556\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mFunctional\u001b[0m)        │ \u001b[38;5;34m15000\u001b[0m)            │            │ transformer_enco… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,502,000</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">132,656</span> │ positional_embed… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,230,556</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">15000</span>)            │            │ transformer_enco… │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,865,212\u001b[0m (18.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865,212</span> (18.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,865,212\u001b[0m (18.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,865,212</span> (18.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"epochs =20\ntransformer.fit(train_ds.repeat(),\n                epochs = epochs,\n                steps_per_epoch=500, \n                validation_data = val_ds.repeat(),\n               validation_steps = 20,\n               callbacks =tf.keras.callbacks.EarlyStopping(patience=3)\n               )","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:13:45.559605Z","iopub.execute_input":"2024-09-28T11:13:45.560022Z","iopub.status.idle":"2024-09-28T11:15:48.460989Z","shell.execute_reply.started":"2024-09-28T11:13:45.559983Z","shell.execute_reply":"2024-09-28T11:15:48.460075Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1727522032.458967      94 service.cc:145] XLA service 0x7cbe9c008b10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1727522032.459023      94 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nW0000 00:00:1727522033.305982      94 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 16/500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4701 - loss: 8.7711      ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727522038.543730      94 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m499/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6731 - loss: 3.4540","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1727522044.395269      94 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.6733 - loss: 3.4492 - val_accuracy: 0.7682 - val_loss: 1.5082\nEpoch 2/20\n\u001b[1m138/500\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7701 - loss: 1.5483","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1727522047.197722      94 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7766 - loss: 1.4890 - val_accuracy: 0.8118 - val_loss: 1.1742\nEpoch 3/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8065 - loss: 1.2443 - val_accuracy: 0.8339 - val_loss: 0.9876\nEpoch 4/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8304 - loss: 1.0309 - val_accuracy: 0.8498 - val_loss: 0.8845\nEpoch 5/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8410 - loss: 0.9461 - val_accuracy: 0.8611 - val_loss: 0.7920\nEpoch 6/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8550 - loss: 0.8494 - val_accuracy: 0.8725 - val_loss: 0.7086\nEpoch 7/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8681 - loss: 0.7342 - val_accuracy: 0.8767 - val_loss: 0.6698\nEpoch 8/20\n\u001b[1m498/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8721 - loss: 0.7061","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1727522086.248184      93 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.8721 - loss: 0.7060 - val_accuracy: 0.8836 - val_loss: 0.6032\nEpoch 9/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8820 - loss: 0.6315 - val_accuracy: 0.8872 - val_loss: 0.5740\nEpoch 10/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8867 - loss: 0.5952 - val_accuracy: 0.8881 - val_loss: 0.5672\nEpoch 11/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8878 - loss: 0.5849 - val_accuracy: 0.8859 - val_loss: 0.5848\nEpoch 12/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8976 - loss: 0.5074 - val_accuracy: 0.8953 - val_loss: 0.5469\nEpoch 13/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8959 - loss: 0.5169 - val_accuracy: 0.9004 - val_loss: 0.5004\nEpoch 14/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.8974 - loss: 0.5083 - val_accuracy: 0.8989 - val_loss: 0.5148\nEpoch 15/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9042 - loss: 0.4550 - val_accuracy: 0.8996 - val_loss: 0.4993\nEpoch 16/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9021 - loss: 0.4699 - val_accuracy: 0.9007 - val_loss: 0.4915\nEpoch 17/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9057 - loss: 0.4487 - val_accuracy: 0.9031 - val_loss: 0.4900\nEpoch 18/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9092 - loss: 0.4191 - val_accuracy: 0.8979 - val_loss: 0.5312\nEpoch 19/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9083 - loss: 0.4303 - val_accuracy: 0.8990 - val_loss: 0.5131\nEpoch 20/20\n\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9149 - loss: 0.3855 - val_accuracy: 0.9019 - val_loss: 0.4953\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cbf1baa5120>"},"metadata":{}}]},{"cell_type":"code","source":"transformer.save_weights('english_french_model.weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:16:03.429224Z","iopub.execute_input":"2024-09-28T11:16:03.429586Z","iopub.status.idle":"2024-09-28T11:16:03.644346Z","shell.execute_reply.started":"2024-09-28T11:16:03.429550Z","shell.execute_reply":"2024-09-28T11:16:03.643318Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"transformer.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:16:04.994126Z","iopub.execute_input":"2024-09-28T11:16:04.994777Z","iopub.status.idle":"2024-09-28T11:16:05.861533Z","shell.execute_reply.started":"2024-09-28T11:16:04.994737Z","shell.execute_reply":"2024-09-28T11:16:05.860757Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[1m170/170\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.4832\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[0.4961366355419159, 0.9027403593063354]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}